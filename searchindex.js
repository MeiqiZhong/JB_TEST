Search.setIndex({"alltitles": {"A simple self-attention mechanism without trainable weights": [[1, "a-simple-self-attention-mechanism-without-trainable-weights"]], "Acknowledgements": [[9, "acknowledgements"]], "Acknowledgments": [[1, "acknowledgments"], [3, "acknowledgments"], [4, "acknowledgments"], [6, "acknowledgments"], [7, "acknowledgments"], [8, "acknowledgments"], [11, "acknowledgments"], [13, "acknowledgments"], [14, "acknowledgments"], [15, "acknowledgments"]], "Adding shortcut connections": [[6, "adding-shortcut-connections"]], "Advantages": [[15, "advantages"]], "Advantages and Disadvantage of Word Embeddings": [[15, "advantages-and-disadvantage-of-word-embeddings"]], "Applying a causal attention mask": [[1, "applying-a-causal-attention-mask"]], "Architecture of LLM": [[5, "architecture-of-llm"]], "Attending to different parts of the input with self-attention": [[1, "attending-to-different-parts-of-the-input-with-self-attention"]], "BERT": [[3, "bert"]], "Broad Sense": [[5, "broad-sense"]], "Build Sequence Dataset: pad_seq etc.": [[3, "build-sequence-dataset-pad-seq-etc"]], "Build a model": [[12, "build-a-model"]], "Building vectors": [[13, "building-vectors"]], "Calculating the text generation loss: cross entropy, and perplexity": [[7, "calculating-the-text-generation-loss-cross-entropy-and-perplexity"]], "Calculating the training and validation set losses": [[7, "calculating-the-training-and-validation-set-losses"]], "Capturing data dependencies with attention mechanisms": [[1, "capturing-data-dependencies-with-attention-mechanisms"]], "Chatbots": [[13, "chatbots"]], "Classification": [[13, "classification"]], "Code": [[13, "code"]], "Coding Attention Mechanisms": [[1, "coding-attention-mechanisms"]], "Coding an LLM architecture": [[6, "coding-an-llm-architecture"]], "Coding the GPT model": [[6, "coding-the-gpt-model"]], "Common NLTK preprocessing steps": [[14, "common-nltk-preprocessing-steps"]], "Components of NLP": [[13, "components-of-nlp"]], "Computing attention weights for all input tokens": [[1, "computing-attention-weights-for-all-input-tokens"]], "Computing the attention weights step by step": [[1, "computing-the-attention-weights-step-by-step"]], "Conclusion": [[4, "conclusion"], [9, "conclusion"]], "Connecting attention and linear layers in a transformer block": [[6, "connecting-attention-and-linear-layers-in-a-transformer-block"]], "Constructing LLMs: A Process Overview": [[5, "constructing-llms-a-process-overview"]], "Continuous Bag of Words(CBOW)": [[15, "continuous-bag-of-words-cbow"]], "Converting to Lowercase": [[9, "converting-to-lowercase"]], "Decoding strategies to control randomness": [[7, "decoding-strategies-to-control-randomness"]], "Disadvantages": [[15, "disadvantages"]], "Discourse": [[13, "discourse"]], "Does our transformer \u201cunderstand\u201d part-of-speech?": [[3, "does-our-transformer-understand-part-of-speech"]], "Download the Dataset": [[10, "download-the-dataset"]], "Download the data": [[12, "download-the-data"]], "Downloading Packages": [[9, "downloading-packages"]], "Evaluating generative text models": [[7, "evaluating-generative-text-models"]], "Experiments": [[4, "experiments"]], "Extending single-head attention to multi-head attention": [[1, "extending-single-head-attention-to-multi-head-attention"]], "Fake News and Hate Speech Detection": [[13, "fake-news-and-hate-speech-detection"]], "GPT2": [[3, "gpt2"]], "Generalize to all input sequence tokens:": [[1, "generalize-to-all-input-sequence-tokens"]], "Generating text": [[6, "generating-text"]], "GloVe": [[15, "glove"]], "Hiding future words with causal attention": [[1, "hiding-future-words-with-causal-attention"]], "How do LLMs Work?": [[5, "how-do-llms-work"]], "Implementing a GPT model from Scratch To Generate Text": [[6, "implementing-a-gpt-model-from-scratch-to-generate-text"]], "Implementing a compact SelfAttention class": [[1, "implementing-a-compact-selfattention-class"]], "Implementing a compact causal self-attention class": [[1, "implementing-a-compact-causal-self-attention-class"]], "Implementing a feed forward network with GELU activations": [[6, "implementing-a-feed-forward-network-with-gelu-activations"]], "Implementing multi-head attention with weight splits": [[1, "implementing-multi-head-attention-with-weight-splits"]], "Implementing self-attention with trainable weights": [[1, "implementing-self-attention-with-trainable-weights"]], "Import and EDA": [[11, "import-and-eda"]], "Information Retrieval and Document Ranking": [[13, "information-retrieval-and-document-ranking"]], "Inner structure of BERT": [[3, "inner-structure-of-bert"]], "Inner structure of GPTmodel": [[3, "inner-structure-of-gptmodel"]], "Install and Import Libraries": [[10, "install-and-import-libraries"]], "Introduction": [[5, "introduction"]], "Knowledge bases, entities and relations": [[13, "knowledge-bases-entities-and-relations"]], "Large Language Models Basic": [[2, "large-language-models-basic"]], "Learning rate warm-up": [[4, "learning-rate-warm-up"]], "Lemmatization": [[9, "lemmatization"], [14, "lemmatization"]], "Let BERT do a cloze test": [[3, "let-bert-do-a-cloze-test"]], "Let GPT say something": [[3, "let-gpt-say-something"]], "Loading": [[3, "loading"]], "Loading and saving model weights in PyTorch": [[7, "loading-and-saving-model-weights-in-pytorch"]], "Loading pretrained weights from Open AI": [[7, "loading-pretrained-weights-from-open-ai"]], "Main process": [[12, "main-process"]], "Masking additional attention weights with dropout": [[1, "masking-additional-attention-weights-with-dropout"]], "Model": [[13, "model"]], "Model Training and Evaluation": [[10, "model-training-and-evaluation"]], "Modifying the text generation function": [[7, "modifying-the-text-generation-function"]], "NLTK preprocessing example code": [[14, "nltk-preprocessing-example-code"]], "NLTK preprocessing pipeline example": [[14, "nltk-preprocessing-pipeline-example"]], "Named Entity Recognition(NER)": [[14, "named-entity-recognition-ner"]], "Narrow sense": [[5, "narrow-sense"]], "Natural Language Processing": [[13, "natural-language-processing"]], "Normalizing activations with layer normalization": [[6, "normalizing-activations-with-layer-normalization"]], "Numericalization": [[11, "numericalization"]], "Overcoming NLP challenges": [[13, "overcoming-nlp-challenges"]], "Part Of Speech Tagging": [[14, "part-of-speech-tagging"]], "Play with Pre-trained transformers language models": [[3, "play-with-pre-trained-transformers-language-models"]], "Positional encoding": [[4, "positional-encoding"]], "Pragmatics": [[13, "pragmatics"]], "Pretraining on Unlabeled Data": [[7, "pretraining-on-unlabeled-data"]], "Probabilistic Generative Grammar": [[3, "probabilistic-generative-grammar"]], "Project: Beginner\u2019s Guide to Text Pre-Processing": [[9, "project-beginners-guide-to-text-pre-processing"]], "Project: Classify Medium Articles with Embeddings": [[10, "project-classify-medium-articles-with-embeddings"]], "Project: Getting Start NLP with classification task": [[11, "project-getting-start-nlp-with-classification-task"]], "Project: News topic classification tasks": [[12, "project-news-topic-classification-tasks"]], "Putting it all together": [[9, "putting-it-all-together"]], "PyTorch Lightning Module": [[4, "pytorch-lightning-module"]], "Remove stop words": [[14, "remove-stop-words"]], "Removing Accented Characters": [[9, "removing-accented-characters"]], "Removing Punctuation": [[9, "removing-punctuation"]], "Removing Special & Non-Alphanumeric Characters": [[9, "removing-special-non-alphanumeric-characters"]], "Research trend": [[4, "research-trend"]], "Sample from probabilistic generative grammar": [[3, "sample-from-probabilistic-generative-grammar"]], "Say Something? (or I\u2019m Giving Up On You)": [[3, "say-something-or-i-m-giving-up-on-you"]], "Self study": [[4, "self-study"]], "Semantics": [[13, "semantics"]], "Sequence to Sequence": [[4, "sequence-to-sequence"]], "Set Anomaly Detection": [[4, "set-anomaly-detection"]], "Skip-Gram": [[15, "skip-gram"]], "Stacking multiple single-head attention layers": [[1, "stacking-multiple-single-head-attention-layers"]], "Stemming": [[9, "stemming"], [14, "stemming"]], "Stopword Removal": [[9, "stopword-removal"]], "Syntax": [[13, "syntax"]], "TF-IDF": [[8, "tf-idf"]], "TF-IDF Example": [[8, "tf-idf-example"]], "TF-IDF is a Heuristic": [[8, "tf-idf-is-a-heuristic"]], "TF-IDF\uff08Term frequency-inverse document frequency \uff09": [[8, "tf-idf-term-frequency-inverse-document-frequency"]], "Temperature scaling": [[7, "temperature-scaling"]], "Test and validation sets": [[11, "test-and-validation-sets"]], "Text Preprocessing": [[13, "text-preprocessing"], [14, "text-preprocessing"]], "Text Preprocessing and Train/Test Split": [[10, "text-preprocessing-and-train-test-split"]], "Text Reasoning": [[13, "text-reasoning"]], "Text-to-Data and viceversa": [[13, "text-to-data-and-viceversa"]], "Text-to-Text Generation": [[13, "text-to-text-generation"]], "The Transformer architecture": [[4, "the-transformer-architecture"]], "The problem with modeling long sequences": [[1, "the-problem-with-modeling-long-sequences"]], "Tokenization": [[9, "tokenization"], [11, "tokenization"], [14, "tokenization"]], "Tokenization: map words to numbers": [[3, "tokenization-map-words-to-numbers"]], "Top-k sampling": [[7, "top-k-sampling"]], "Topics and Keywords": [[13, "topics-and-keywords"]], "Train a transformer on this language": [[3, "train-a-transformer-on-this-language"]], "Train a transformer to \u201cspeak your own language\u201d!": [[3, "train-a-transformer-to-speak-your-own-language"]], "Training": [[12, "training"]], "Training & Validation Functions": [[12, "training-validation-functions"]], "Training an LLM": [[7, "training-an-llm"]], "Training our model": [[11, "training-our-model"]], "Transformer": [[4, "transformer"]], "Transformer Encoder": [[4, "transformer-encoder"]], "Transformers for Language Modelling": [[3, "transformers-for-language-modelling"]], "Using GPT to generate text": [[7, "using-gpt-to-generate-text"]], "Welcome to ZMQ\u2019s NLP": [[0, "welcome-to-zmq-s-nlp"]], "What are large language models (LLMs)?": [[5, "what-are-large-language-models-llms"]], "What is NLP\u2019s tasks?": [[13, "what-is-nlp-s-tasks"]], "What is Natural Language Processing?": [[13, "what-is-natural-language-processing"]], "Why Text Pre-processing?": [[9, "why-text-pre-processing"]], "Word embedding": [[15, "word-embedding"]], "Word2Vec": [[15, "word2vec"]], "Work with datasets": [[12, "work-with-datasets"]], "Your turn! \ud83d\ude80": [[1, "your-turn"], [3, "your-turn"], [4, "your-turn"], [6, "your-turn"], [7, "your-turn"], [8, "your-turn"], [13, "your-turn"], [14, "your-turn"], [15, "your-turn"]], "Zipf\u2019s Law": [[8, "zipfs-law"]], "Zipf\u2019s Law in Brown Corpus": [[8, "zipfs-law-in-brown-corpus"]], "Zipf\u2019s Law in Medium Articles": [[8, "zipfs-law-in-medium-articles"]], "Zipf\u2019s law and Stopwords": [[8, "zipfs-law-and-stopwords"]], "generate_batch": [[12, "generate-batch"]], "packages": [[12, "packages"]]}, "docnames": ["index", "notebook/Large_Language_Model/basic/attention", "notebook/Large_Language_Model/basic/basic", "notebook/Large_Language_Model/basic/language-modelling", "notebook/Large_Language_Model/basic/transformer", "notebook/Large_Language_Model/introduction", "notebook/Large_Language_Model/pretrained-model/implementing-a-GPT-model", "notebook/Large_Language_Model/pretrained-model/pretraining-on-unlabeled-data", "notebook/Natural_Language_Processing/TF-IDF", "notebook/Natural_Language_Processing/assignments/beginner-guide-to-text-preprocessing", "notebook/Natural_Language_Processing/assignments/embedding_project", "notebook/Natural_Language_Processing/assignments/getting-start-nlp-with-classification-task", "notebook/Natural_Language_Processing/assignments/news-topic-classification-tasks", "notebook/Natural_Language_Processing/nlp", "notebook/Natural_Language_Processing/text-preprocessing", "notebook/Natural_Language_Processing/word-embedding"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["index.md", "notebook/Large_Language_Model/basic/attention.ipynb", "notebook/Large_Language_Model/basic/basic.ipynb", "notebook/Large_Language_Model/basic/language-modelling.ipynb", "notebook/Large_Language_Model/basic/transformer.ipynb", "notebook/Large_Language_Model/introduction.ipynb", "notebook/Large_Language_Model/pretrained-model/implementing-a-GPT-model.ipynb", "notebook/Large_Language_Model/pretrained-model/pretraining-on-unlabeled-data.ipynb", "notebook/Natural_Language_Processing/TF-IDF.ipynb", "notebook/Natural_Language_Processing/assignments/beginner-guide-to-text-preprocessing.ipynb", "notebook/Natural_Language_Processing/assignments/embedding_project.ipynb", "notebook/Natural_Language_Processing/assignments/getting-start-nlp-with-classification-task.ipynb", "notebook/Natural_Language_Processing/assignments/news-topic-classification-tasks.ipynb", "notebook/Natural_Language_Processing/nlp.ipynb", "notebook/Natural_Language_Processing/text-preprocessing.ipynb", "notebook/Natural_Language_Processing/word-embedding.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 3, 4, 5, 6, 7, 10, 11, 12, 14, 15], "0": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15], "00": [4, 8, 9, 10, 11], "000": [7, 8, 10, 12], "0000": [1, 6, 7], "00000": 7, "000000": 7, "000005": 7, "00001": 7, "000010": 7, "000015": 7, "000020": 7, "000025": 7, "000030": 7, "000035": 7, "000040": 7, "000045": 7, "000050": 7, "000055": 7, "000060": 7, "000065": 7, "000070": 7, "000075": 7, "000080": 7, "000085": 7, "0001201116101583466": 6, "00020173587836325169": 6, "00026011": 11, "00026941": 11, "00031829": 11, "00042677": 11, "0004774e": 15, "0004859": 11, "00048828": 11, "00052738": 11, "0007152041653171182": 6, "00075388": 11, "00082207": 11, "00085592": 11, "00094271": 11, "0012": 6, "00138378": 11, "001398873864673078": 6, "00168324": 11, "0032": 6, "00329781": 11, "0034534931182861": 3, "00348282": 11, "00421906e": 11, "0043602": 11, "00440216": 11, "0048317909240723": 3, "0049057": 11, "005049646366387606": 6, "0057": 6, "0058": 1, "0077": 6, "0078": 1, "0080514e": 15, "009": 6, "0095028e": 15, "01": [4, 8, 9, 10, 11, 15], "0111": 6, "0126": 8, "013523817062378": 3, "0139": 6, "0153": 8, "0162": 6, "017181396484375": 3, "0174": 6, "0177": 1, "0181": 6, "0186": 1, "0189": 6, "0198": 1, "02": [3, 8, 10], "0209": 6, "021973": 11, "022443": 11, "0231": 6, "023286": 11, "0237": 6, "0252": 8, "026275": 11, "0267317e": 15, "0268": 6, "0270079374313354": 3, "027095822617411613": 3, "028294563293457": 3, "0293": 6, "03": [8, 10, 11, 15], "0306": 8, "0320098400115967": 3, "033979892730713": 3, "0344244": 15, "03608504": 15, "0366766452789307": 3, "036801": 4, "038146": 4, "0390": 1, "039162": 4, "039600": 11, "0398": 6, "04": [4, 8, 10, 11, 15], "0400": 6, "0402": 1, "0425397e": 15, "0435": 6, "044715": [6, 7], "04667223244905472": 3, "05": [1, 3, 4, 7, 8, 10, 11, 15], "051": 7, "0524795055389404": 3, "05338377505540848": 3, "0535675287246704": 3, "05377960e": 11, "0541567e": 15, "05447388e": 11, "054729700088501": 3, "0558038e": 15, "0561695e": 15, "0568015575408936": 3, "0571255683898926": 3, "0596": 6, "06": [4, 7, 8, 10], "0605": 1, "0610": 6, "0615": 7, "0620": 1, "0632": 1, "0647740364074707": 3, "0662739276885986": 3, "0679": 1, "0685": 1, "0693": 1, "06d": 7, "07": [8, 10], "0702": 1, "0703": 1, "0708": 6, "0713": 1, "0718233585357666": 3, "0739": 1, "0748": 1, "0749": 1, "0754": 1, "0755290e": 15, "0760": 1, "0763": 1, "0772": 1, "0777372121810913": 3, "0786": 1, "07897425": 15, "0795": 1, "08": [6, 10], "0811495780944824": 3, "081486701965332": 3, "0839": 6, "0843": 1, "0856168e": 15, "0865": 1, "0874": 1, "0876": 6, "08774460107088089": 3, "0882": 1, "0891": 6, "09": [8, 10], "0906": 1, "0908": 6, "0920": 6, "0923397541046143": 3, "0955264568328857": 3, "0981": 1, "0982": 6, "0988": 1, "0m": [8, 9, 10, 15], "1": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [1, 3, 4, 6, 7, 10, 11, 12, 14, 15], "100": [4, 6, 7, 12, 15], "1000": [4, 7, 10], "10000": 4, "1024": [1, 3, 6, 7], "102530": 11, "103": 7, "1036": 1, "10457": 12, "1046": 12, "105": [10, 14], "1055666208267212": 3, "1056964e": 15, "106": [10, 11, 14], "1061e": 7, "1063": 1, "107": [10, 14], "10731107741594315": 3, "1077": 1, "108": 14, "1081": 1, "1082": 1, "1084500551223755": 3, "10k": 4, "11": [3, 6, 7, 10, 13, 15], "1107": 7, "1108": 1, "110844373703003": 3, "1110": 6, "1114088296890259": 3, "1121": 6, "113": 12, "11311": 7, "1141964197158813": 3, "114224": 11, "1152591705322266": 3, "116": 10, "116552710533142": 3, "1170190e": 15, "11715698e": 11, "117m": 6, "1183097e": 15, "1192": 6, "12": [3, 4, 6, 7, 8, 10, 14, 15], "120": [7, 12], "1220": 1, "1226": 6, "123": [1, 6, 7], "124": [6, 7], "1240": 1, "1242": 1, "124m": [6, 7], "1251": 6, "1255787e": 15, "126000": 10, "1260128021240234": 3, "1263": 1, "1269": 12, "127": 10, "1270": 1, "128": [3, 4, 6, 7, 11], "1280": [6, 7], "1285": 1, "129": 7, "1290": 1, "1295": 1, "1296": 6, "13": [3, 8, 10, 15], "1300131294": [7, 11, 13, 15], "1303": 6, "1304744e": 15, "1308": 7, "1311": 1, "1311514377593994": 3, "131159782409668": 3, "132000": 10, "1324": 6, "1326050758361816": 3, "133": 10, "135": 8, "1367": 1, "1371004581451416": 3, "1385": 1, "1390": 1, "139648634296128": 4, "14": [3, 4, 8, 10, 12, 14, 15], "140": 14, "141": 14, "1416406631469727": 3, "142": 14, "1420": 1, "14206451": 15, "143": 14, "1435": 1, "144000": 8, "1441": 6, "145": 7, "1452": 1, "1455": 1, "1460": 12, "1462": 1, "1477": 1, "1479": 1, "1480": 1, "1496": 1, "1498": 1, "15": [1, 3, 4, 7, 8, 9, 10, 15], "1500": 1, "150mb": 4, "1510": 1, "15119934e": 11, "1516095399856567": 3, "152": 11, "1526": 1, "15271": 12, "1529": 1, "1533219814300537": 3, "1542": 1, "15496": 6, "1550": 1, "1558m": 7, "1563e": 7, "1564": 1, "1565": 1, "1571": 1, "1581": 1, "1582": 12, "1585": 1, "1586": 6, "1588": 1, "1591": 8, "15966": 8, "16": [3, 4, 6, 7, 8, 10, 12, 15], "160": 6, "1600": [6, 7], "163": [6, 14], "1631": 1, "1633579e": 15, "16341": 12, "16342": 12, "163m": 6, "164": 14, "1645092e": 15, "1646": 1, "165": [7, 14], "1652": 1, "1652735471725464": 3, "16550446e": 11, "1656": 1, "1658": 1, "1659": 1, "166": 14, "1661": 1, "1662": 1, "1663": 1, "1664": 1, "1664648e": 15, "1665": 1, "16657": 7, "1666": 1, "1667": 1, "1668": 1, "1669": 1, "167": 14, "1670": 1, "168": 14, "16833": 7, "169": 14, "17": [3, 4, 8, 10, 15], "1703": 1, "171": 10, "1710952e": 15, "172": 10, "1720": 1, "1721": 1, "1723": 1, "1731": 1, "173909": 8, "1740601062774658": 3, "1769912e": 15, "1794": 6, "1798": 6, "18": [3, 8, 10, 15], "1813908815383911": 3, "1814": 6, "1820": 1, "18288803e": 11, "1830": 1, "184": 7, "18424606e": 11, "185": 12, "1861": 6, "1867": 11, "1869": 1, "1879": 1, "1888": 1, "1888813972473145": 3, "1894": 6, "1895": 6, "1896": 1, "19": [1, 3, 4, 7, 8, 9, 10, 14, 15], "192": 8, "1921": 1, "1935": 1, "194": [1, 7], "1944": 12, "19447708e": 11, "195": [1, 7], "1954007148742676": 3, "1954584121704102": 3, "1958": 1, "196": [1, 7], "1966": 6, "1971": 1, "1975": 1, "1981": 1, "1983": 1, "1984": 1, "1998": 6, "1_000": 7, "1e": [3, 4, 6, 7], "1f": 12, "1k": 4, "2": [0, 1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "20": [3, 6, 7, 10, 15], "200": 12, "2000": [4, 10], "2006": 1, "2015": 4, "2016": [6, 8], "2017": [4, 10], "2018": [3, 4, 8], "2019": [4, 10], "2020": [4, 8, 10, 15], "2021": [8, 9], "2022": [10, 15], "2023": 10, "2024": [9, 10], "2024897e": 15, "202561616897583": 3, "2034": 6, "2036": 1, "2036733627319336": 3, "2038": 12, "204": 7, "2041": 1, "2046": 1, "2047": 3, "20479": 7, "2048": 8, "20639801e": 11, "20694105327129364": 6, "2074": 1, "2098": 1, "20explor": 15, "21": [1, 3, 10, 12, 15], "2128": 1, "2133": 6, "2150": 1, "2159011363983154": 3, "2170": 6, "2175": 1, "2183": [1, 6], "2184": 1, "2186": 11, "2187308073043823": 3, "2199": 1, "22": [1, 3, 7, 8, 10, 15], "22067261e": 11, "221": 7, "2216": [1, 6], "22169792652130127": 6, "2223633527755737": 3, "224": 4, "2249": 1, "224x224": 4, "225": 4, "2250": 6, "2256550e": 15, "2260": 6, "2264": 1, "227": 7, "2278": 1, "228": 12, "229": 4, "2290826e": 15, "23": [1, 3, 10, 12, 15], "2318": 1, "2319": 1, "2326": 1, "2327": 12, "2333": 1, "2350927591323853": 3, "236": 7, "2367809e": 15, "2369": 1, "23702": 11, "2379": 1, "239": 7, "2390": 6, "2392": 6, "2394": 6, "24": [3, 4, 6, 7, 8, 10, 11, 15], "2401": 11, "2407": 6, "24086": 6, "2430": 6, "2439": 6, "2460": 1, "2462": 1, "2484600e": 15, "25": [1, 3, 6, 7, 8, 10, 11, 15], "2531900e": 15, "2535": 3, "2544509e": 15, "256": [4, 6, 7, 11], "2561": 7, "2564054e": 15, "257": [6, 7], "2575": 1, "259561061859131": 3, "25h": [9, 10], "25hdownload": [8, 9, 10], "25hrequir": 10, "25l": [8, 9, 10], "26": [3, 7, 10, 15], "260": [7, 11], "2606": 6, "2639": 1, "2642": 1, "265": 11, "2650562524795532": 3, "2665732502937317": 6, "26769257e": 11, "268": 7, "26835": 11, "269": 11, "2693": 1, "2696": 6, "2698": 6, "27": [3, 10, 15], "27018": 6, "2705": 1, "2719969749450684": 3, "2727038860321045": 3, "27354": 11, "27355957e": 11, "27381897e": 11, "2745": 1, "2758": 1, "2767992e": 15, "2775": 1, "28": [3, 7, 10, 13, 15], "2800": 7, "2820688486099243": 3, "2839810848236084": 3, "2853527069091797": 3, "2856": 1, "2879": 1, "289": 11, "2899": 1, "29": [3, 8, 10, 15], "2912": 6, "2927": 1, "29340": 11, "2935": 1, "294": 11, "2940": 6, "2943": 1, "2948": 1, "295": 7, "2963616847991943": 3, "29669": 7, "29780579e": 11, "298": 12, "2986": 3, "2988": 6, "299": 11, "2990": 1, "2996": 1, "2d": 1, "2f": [4, 6], "2k": [8, 9, 10], "2nd": 1, "2t": 1, "3": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "30": [3, 4, 7, 8, 10, 15], "30000": [8, 11], "301": 9, "3022": 6, "3041": 6, "30522": 3, "3058": 1, "3061": 1, "3072": 3, "3084": 1, "309": 12, "30961": 6, "3097": 1, "31": [3, 4, 10, 15], "310": 7, "3103": 1, "3120929e": 15, "314": 6, "3162024021148682": 3, "319": 7, "3190": 1, "3199472e": 15, "31m": [8, 9, 10, 15], "31m10": 10, "31m103": 10, "31m108": 10, "31m11": 10, "31m116": 10, "31m118": 10, "31m12": [9, 10], "31m121": 10, "31m124": 10, "31m125": 10, "31m129": 10, "31m13": 10, "31m130": 10, "31m133": 10, "31m136": 10, "31m138": 10, "31m14": 10, "31m142": 10, "31m15": 10, "31m16": 10, "31m17": 10, "31m18": 10, "31m19": 10, "31m2": 9, "31m20": 10, "31m21": 10, "31m22": [9, 10], "31m23": 10, "31m24": 10, "31m25": 10, "31m26": [9, 10], "31m27": 10, "31m29": 10, "31m3": [8, 10], "31m31": [9, 10], "31m32": 10, "31m34": 10, "31m37": 10, "31m39": 10, "31m4": [8, 10], "31m43": 10, "31m44": 10, "31m46": 10, "31m47": 10, "31m48": 10, "31m49": 10, "31m5": [8, 10], "31m51": 10, "31m53": 10, "31m54": 10, "31m57": 10, "31m6": 10, "31m60": 10, "31m61": 9, "31m64": 10, "31m65": 10, "31m66": 10, "31m69": 10, "31m7": 10, "31m70": 10, "31m72": 10, "31m73": 10, "31m76": 10, "31m8": 10, "31m85": 10, "31m88": 9, "31m9": 10, "31m91": 10, "31merror": 15, "32": [3, 4, 7, 10, 15], "320": 7, "3201": 6, "3208": 1, "3216276168823242": 3, "3219751e": 4, "3219831e": 4, "3233": 6, "3240929e": 15, "3257": 1, "3258541822433472": 6, "328": 7, "32896995544433594": 6, "3297": 6, "32m0": [8, 9, 10], "32m1": [8, 9, 10], "32m10": [8, 10], "32m100": 10, "32m102": 10, "32m104": 10, "32m105": 10, "32m107": 10, "32m109": 10, "32m11": 8, "32m110": 10, "32m112": 10, "32m114": 10, "32m116": 10, "32m117": 10, "32m118": 10, "32m12": [8, 10], "32m120": 10, "32m121": 10, "32m122": 10, "32m123": 10, "32m124": 10, "32m125": 10, "32m126": 10, "32m127": 10, "32m128": 10, "32m129": 10, "32m13": 8, "32m130": 10, "32m131": 10, "32m132": 10, "32m133": 10, "32m134": 10, "32m135": 10, "32m136": 10, "32m137": 10, "32m138": 10, "32m139": 10, "32m14": [8, 10], "32m140": 10, "32m141": 10, "32m142": 10, "32m143": 10, "32m144": 10, "32m145": 10, "32m146": 10, "32m147": 10, "32m148": 10, "32m149": 10, "32m15": 8, "32m150": 10, "32m151": 10, "32m152": 10, "32m153": 10, "32m154": 10, "32m155": 10, "32m156": 10, "32m157": 10, "32m158": 10, "32m159": 10, "32m16": [8, 10], "32m160": 10, "32m161": 10, "32m162": 10, "32m163": 10, "32m164": 10, "32m165": 10, "32m166": 10, "32m167": 10, "32m168": 10, "32m169": 10, "32m170": 10, "32m171": 10, "32m172": 10, "32m173": 10, "32m174": 10, "32m175": 10, "32m176": 10, "32m177": 10, "32m178": 10, "32m179": 10, "32m180": 10, "32m181": 10, "32m182": 10, "32m183": 10, "32m184": 10, "32m185": 10, "32m186": 10, "32m187": 10, "32m188": 10, "32m189": 10, "32m19": 10, "32m190": 10, "32m191": 10, "32m192": 10, "32m193": 10, "32m194": 10, "32m195": 10, "32m196": 10, "32m197": 10, "32m198": 10, "32m199": 10, "32m2": [8, 10], "32m20": 10, "32m200": 10, "32m201": 10, "32m202": 10, "32m203": 10, "32m204": 10, "32m205": 10, "32m206": 10, "32m207": 10, "32m208": 10, "32m209": 10, "32m210": 10, "32m211": 10, "32m212": 10, "32m213": 10, "32m214": 10, "32m215": 10, "32m216": 10, "32m217": 10, "32m218": 10, "32m219": 10, "32m220": 10, "32m221": 10, "32m222": 10, "32m223": 10, "32m224": 10, "32m225": 10, "32m226": 10, "32m227": 10, "32m228": 10, "32m229": 10, "32m230": 10, "32m231": 10, "32m232": 10, "32m233": 10, "32m234": 10, "32m235": 10, "32m236": 10, "32m237": 10, "32m238": 10, "32m239": 10, "32m24": 10, "32m240": 10, "32m241": 10, "32m242": 10, "32m243": 10, "32m244": 10, "32m245": 10, "32m246": 10, "32m247": 10, "32m248": 10, "32m249": 10, "32m25": 10, "32m250": 10, "32m251": 10, "32m252": 10, "32m253": 10, "32m254": 10, "32m255": 10, "32m256": 10, "32m257": 10, "32m258": 10, "32m259": 10, "32m260": 10, "32m261": 10, "32m262": 10, "32m263": 10, "32m264": 10, "32m265": 10, "32m266": 10, "32m267": 10, "32m268": 10, "32m269": 10, "32m270": 10, "32m271": 10, "32m272": 10, "32m273": 10, "32m274": 10, "32m275": 10, "32m276": 10, "32m277": 10, "32m278": 10, "32m279": 10, "32m28": 10, "32m280": 10, "32m281": 10, "32m282": 10, "32m283": 10, "32m284": 10, "32m285": 10, "32m286": 10, "32m287": 10, "32m288": 10, "32m289": 10, "32m29": 10, "32m290": 10, "32m291": 10, "32m292": 10, "32m293": 10, "32m294": 10, "32m295": 10, "32m296": 10, "32m297": 10, "32m298": 10, "32m299": 10, "32m3": 8, "32m300": 10, "32m301": [9, 10], "32m302": 10, "32m303": 10, "32m304": 10, "32m305": 10, "32m306": 10, "32m307": 10, "32m308": 10, "32m309": 10, "32m31": 10, "32m310": 10, "32m311": 10, "32m312": 10, "32m313": 10, "32m314": 10, "32m315": 10, "32m316": 10, "32m317": 10, "32m318": 10, "32m319": 10, "32m320": 10, "32m321": 10, "32m322": 10, "32m323": 10, "32m324": 10, "32m325": 10, "32m326": 10, "32m327": 10, "32m328": 10, "32m329": 10, "32m33": 10, "32m330": 10, "32m331": 10, "32m332": 10, "32m333": 10, "32m334": 10, "32m335": 10, "32m336": 10, "32m337": 10, "32m338": 10, "32m339": 10, "32m34": 10, "32m340": 10, "32m341": 10, "32m342": 10, "32m343": 10, "32m344": 10, "32m345": 10, "32m346": 10, "32m347": 10, "32m348": 10, "32m349": 10, "32m350": 10, "32m351": 10, "32m352": 10, "32m353": 10, "32m354": 10, "32m355": 10, "32m356": 10, "32m357": 10, "32m358": 10, "32m359": 10, "32m36": 10, "32m360": 10, "32m361": 10, "32m362": 10, "32m363": 10, "32m364": 10, "32m365": 10, "32m366": 10, "32m367": 10, "32m368": 10, "32m369": 10, "32m37": 10, "32m370": 10, "32m371": 10, "32m372": 10, "32m373": 10, "32m374": 10, "32m375": 10, "32m376": 10, "32m377": 10, "32m378": 10, "32m379": 10, "32m380": 10, "32m381": 10, "32m382": 10, "32m383": 10, "32m384": 10, "32m385": 10, "32m386": 10, "32m387": 10, "32m388": 10, "32m389": 10, "32m39": 10, "32m390": 10, "32m391": 10, "32m392": 10, "32m393": 10, "32m394": 10, "32m395": 10, "32m396": 10, "32m397": 10, "32m398": 10, "32m399": 10, "32m4": [8, 10], "32m40": [9, 10], "32m400": 10, "32m401": 10, "32m402": 10, "32m403": 10, "32m404": 10, "32m405": 10, "32m406": 10, "32m407": 10, "32m408": 10, "32m409": 10, "32m41": 10, "32m410": 10, "32m411": 10, "32m412": 10, "32m413": 10, "32m414": 10, "32m415": 10, "32m416": 10, "32m417": 10, "32m418": 10, "32m419": 10, "32m420": 10, "32m421": 10, "32m422": 10, "32m423": 10, "32m424": 10, "32m425": 10, "32m426": 10, "32m427": 10, "32m428": 10, "32m429": 10, "32m43": 10, "32m430": 10, "32m431": 10, "32m432": 10, "32m433": 10, "32m434": 10, "32m435": 10, "32m436": 10, "32m437": 10, "32m438": 10, "32m439": 10, "32m440": 10, "32m441": 10, "32m442": 10, "32m443": 10, "32m444": 10, "32m445": 10, "32m446": 10, "32m447": 10, "32m448": 10, "32m449": 10, "32m450": 10, "32m451": 10, "32m452": 10, "32m453": 10, "32m454": 10, "32m455": 10, "32m456": 10, "32m457": 10, "32m458": 10, "32m459": 10, "32m46": 10, "32m460": 10, "32m461": 10, "32m462": 10, "32m463": 10, "32m464": 10, "32m465": 10, "32m466": 10, "32m467": 10, "32m468": 10, "32m469": 10, "32m470": 10, "32m471": 10, "32m472": 10, "32m473": 10, "32m474": 10, "32m475": 10, "32m476": 10, "32m477": 10, "32m478": 10, "32m479": 10, "32m48": 10, "32m480": 10, "32m481": 10, "32m482": 10, "32m483": 10, "32m484": 10, "32m485": 10, "32m486": 10, "32m487": 10, "32m488": 10, "32m489": 10, "32m490": 10, "32m491": 10, "32m492": 10, "32m493": 10, "32m494": 10, "32m495": 10, "32m496": 10, "32m497": 10, "32m498": 10, "32m499": 10, "32m5": [8, 10], "32m50": 10, "32m500": 10, "32m501": 10, "32m502": 10, "32m503": 10, "32m504": 10, "32m505": 10, "32m506": 10, "32m507": 10, "32m508": 10, "32m509": 10, "32m510": 10, "32m511": 10, "32m512": 10, "32m513": 10, "32m514": 10, "32m515": 10, "32m516": 10, "32m517": 10, "32m518": 10, "32m519": 10, "32m52": 10, "32m520": 10, "32m521": 10, "32m522": 10, "32m523": 10, "32m524": 10, "32m525": 10, "32m526": 10, "32m527": 10, "32m528": 10, "32m529": 10, "32m530": 10, "32m531": 10, "32m532": 10, "32m533": 10, "32m534": 10, "32m535": 10, "32m536": 10, "32m537": 10, "32m538": 10, "32m539": 10, "32m540": 10, "32m541": 10, "32m542": 10, "32m543": 10, "32m544": 10, "32m545": 10, "32m546": 10, "32m547": 10, "32m548": 10, "32m549": 10, "32m55": 10, "32m550": 10, "32m551": 10, "32m552": 10, "32m553": 10, "32m554": 10, "32m555": 10, "32m556": 10, "32m557": 10, "32m558": 10, "32m559": 10, "32m560": 10, "32m561": 10, "32m562": 10, "32m563": 10, "32m564": 10, "32m565": 10, "32m566": 10, "32m567": 10, "32m568": 10, "32m569": 10, "32m57": [9, 10], "32m570": 10, "32m571": 10, "32m572": 10, "32m573": 10, "32m574": 10, "32m575": 10, "32m576": 10, "32m577": 10, "32m578": 10, "32m579": 10, "32m580": 10, "32m581": 10, "32m582": 10, "32m583": 10, "32m584": 10, "32m585": 10, "32m586": 10, "32m587": 10, "32m588": 10, "32m589": 10, "32m59": 10, "32m590": 10, "32m591": 10, "32m592": 10, "32m593": 10, "32m594": 10, "32m595": 10, "32m596": 10, "32m597": 10, "32m598": 10, "32m599": 10, "32m6": 8, "32m60": 10, "32m600": 10, "32m601": 10, "32m602": 10, "32m603": 10, "32m604": 10, "32m605": 10, "32m606": 10, "32m607": 10, "32m608": 10, "32m609": 10, "32m61": 10, "32m610": 10, "32m611": 10, "32m612": 10, "32m613": 10, "32m614": 10, "32m615": 10, "32m616": 10, "32m617": 10, "32m618": 10, "32m619": 10, "32m620": 10, "32m621": 10, "32m622": 10, "32m623": 10, "32m624": 10, "32m625": 10, "32m626": 10, "32m627": 10, "32m628": 10, "32m629": 10, "32m630": 10, "32m631": 10, "32m632": 10, "32m633": 10, "32m634": 10, "32m635": 10, "32m636": 10, "32m637": 10, "32m638": 10, "32m639": 10, "32m64": 10, "32m640": 10, "32m641": 10, "32m642": 10, "32m643": 10, "32m644": 10, "32m645": 10, "32m646": 10, "32m647": 10, "32m648": 10, "32m649": 10, "32m650": 10, "32m651": 10, "32m652": 10, "32m653": 10, "32m654": 10, "32m655": 10, "32m656": 10, "32m657": 10, "32m658": 10, "32m659": 10, "32m66": 10, "32m660": 10, "32m661": 10, "32m662": 10, "32m663": 10, "32m664": 10, "32m665": 10, "32m666": 10, "32m667": 10, "32m668": 10, "32m669": 10, "32m670": 10, "32m671": 10, "32m672": 10, "32m673": 10, "32m674": 10, "32m675": 10, "32m676": 10, "32m677": 10, "32m678": 10, "32m679": 10, "32m68": 10, "32m680": 10, "32m681": 10, "32m682": 10, "32m683": 10, "32m684": 10, "32m685": 10, "32m686": 10, "32m687": 10, "32m688": 10, "32m689": 10, "32m690": 10, "32m691": 10, "32m692": 10, "32m693": 10, "32m694": 10, "32m695": 10, "32m696": 10, "32m697": 10, "32m698": 10, "32m699": 10, "32m7": 8, "32m70": 10, "32m700": 10, "32m701": 10, "32m702": 10, "32m703": 10, "32m704": 10, "32m705": 10, "32m706": 10, "32m707": 10, "32m708": 10, "32m709": 10, "32m710": 10, "32m711": 10, "32m712": 10, "32m713": 10, "32m714": 10, "32m715": 10, "32m716": 10, "32m717": 10, "32m718": 10, "32m719": 10, "32m720": 10, "32m721": 10, "32m722": 10, "32m723": 10, "32m724": 10, "32m725": 10, "32m726": 10, "32m727": 10, "32m728": 10, "32m729": 10, "32m73": 10, "32m730": 10, "32m731": 10, "32m732": 10, "32m733": 10, "32m734": 10, "32m735": 10, "32m736": 10, "32m737": 10, "32m738": 10, "32m739": 10, "32m740": 10, "32m741": 10, "32m742": 10, "32m743": 10, "32m744": 10, "32m745": 10, "32m746": 10, "32m747": 10, "32m748": 10, "32m749": 10, "32m75": 10, "32m750": 10, "32m751": 10, "32m752": 10, "32m753": 10, "32m754": 10, "32m755": 10, "32m756": 10, "32m757": 10, "32m758": 10, "32m759": 10, "32m760": 10, "32m761": 10, "32m762": 10, "32m763": 10, "32m764": 10, "32m765": 10, "32m766": 10, "32m767": 10, "32m768": 10, "32m769": 10, "32m77": 10, "32m770": 10, "32m771": 10, "32m772": 10, "32m773": 10, "32m774": [9, 10], "32m775": 10, "32m776": 10, "32m777": 10, "32m778": 10, "32m779": 10, "32m78": 9, "32m8": [8, 10], "32m80": 10, "32m82": 10, "32m84": 10, "32m86": 10, "32m88": 10, "32m9": 8, "32m90": 10, "32m92": 10, "32m93": 10, "32m95": 10, "32m97": 10, "32m98": 10, "32x32": 4, "33": [1, 3, 8, 10, 15], "332": 7, "3327": 1, "333": 12, "3331": 1, "334485650062561": 3, "3355025e": 15, "3358": 12, "336": 11, "3388": 6, "339": 7, "34": [3, 10, 12, 15], "3408": 1, "3428": 1, "343": 7, "345": [6, 7], "346": 11, "3469": 6, "3470": 6, "3474": 1, "34765": 11, "3493": 1, "35": [3, 10, 15], "3507905e": 15, "3533740043640137": 3, "3537": 6, "3545544e": 4, "3545609e": 4, "355m": 7, "3565": [1, 3], "3567": 6, "3581535816192627": 3, "3589": 1, "3593": 1, "3598543e": 15, "36": [3, 4, 6, 7, 10, 11, 15], "36019897e": 11, "3610": 7, "3613892e": 15, "3626": [6, 7], "36473": 11, "3657773e": 15, "3677": 7, "368": 8, "3694": 6, "36d72442aefd8232": 11, "36m": [8, 9, 10], "36m0": [8, 9, 10], "37": [3, 10, 15], "3717": 6, "3718326e": 15, "372": 7, "3737": 1, "3757477e": 15, "3775": 1, "3781307e": 15, "3796": 7, "37d61fd2272659b1": 11, "38": [3, 4, 10, 15], "3800": 1, "3814001083374023": 3, "3818882703781128": 3, "3835302591323853": 3, "38378143e": 11, "384": 10, "385": 4, "3857686519622803": 3, "3860": 1, "3872": 6, "3873": 1, "3880": 12, "3897": 1, "39": [3, 10, 15], "3910599946975708": 3, "392": 12, "3928": 1, "395": 12, "3953868e": 15, "3966": [1, 12], "3d": 1, "3f": [7, 15], "3mm": 4, "4": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "40": [3, 7, 9, 10, 15], "4001122e": 15, "4006121158599854": 3, "401": 10, "40216064e": 11, "4028": 1, "40399": 8, "406": 4, "4062": 6, "4066": 1, "41": [3, 10, 15], "412": 6, "4120527505874634": 3, "4126": 6, "41751": 7, "4177": 1, "4184163e": 15, "42": [3, 4, 7, 8, 10, 11, 15], "420": 7, "420322299003601": 3, "4208158e": 4, "4208173e": 4, "421": 7, "4220": 1, "4231843e": 15, "42348": 6, "4235713481903076": 3, "42387": 12, "42388": 12, "42389": 12, "4267": 6, "42707062e": 11, "4270827e": 15, "428": 7, "42826": 7, "4291316e": 15, "43": [1, 3, 4, 10, 15], "4304": [1, 12], "4306": 1, "4340": 1, "435": 11, "4359247e": 15, "4391": 1, "44": [3, 10, 15], "44001770e": 11, "441": 10, "4419": 1, "4420981407165527": 3, "4421": 1, "4424": 12, "4431": 1, "4432": 6, "445": 11, "447": 7, "44767761e": 11, "4478951e": 15, "4483": 1, "45": [3, 10, 12, 15], "4519": 1, "4530": 6, "4539": 6, "4541e": 7, "4543532e": 4, "4543594e": 4, "4545": 1, "4551": 1, "456": 4, "4570": 1, "4576": 1, "4594": 1, "46": [3, 7, 8, 10, 15], "4606": 1, "4608": 7, "4656": 1, "4667": 6, "4671": 1, "4694128036499023": 3, "4695": 6, "47": [3, 7, 10, 15], "4714618e": 15, "47284": 11, "4735491275787354": 3, "4753": 1, "4754": 1, "4762432e": 15, "47678": 7, "4772": 1, "4773252e": 15, "47843": 6, "479000": 10, "48": [3, 4, 6, 7, 10, 15], "4802629947662354": 3, "4812": 6, "4814906e": 15, "482000": 8, "4827": 3, "48281860e": 11, "4835": 6, "4840": 11, "484283685684204": 3, "485": 4, "48527527e": 11, "4858": 1, "486": 12, "4878454208374023": 3, "49": [3, 4, 8, 10, 15], "490": 7, "4910474e": 15, "4921": 1, "4925": 1, "492750883102417": 3, "4929": 6, "4937": 1, "4950": 1, "4984965e": 15, "49906": 7, "4f": 12, "5": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "50": [1, 3, 4, 6, 7, 10, 11, 12, 15], "500": 4, "5000": 4, "50000": 4, "50256": 3, "50257": [3, 6, 7], "5042": 7, "50489807e": 11, "5066": 6, "5077": 1, "508": 7, "50k": 4, "51": [7, 8, 10, 15], "5100": 7, "5102": 6, "512": [3, 4, 7], "5120": 7, "512395977973938": 3, "5145": 7, "5147674083709717": 3, "515000": 8, "5159": 1, "5173": 6, "5198": 6, "52": [10, 15], "524000": 10, "5266": 1, "5296676e": 15, "5296b0c19e1ce60": 11, "5299": 1, "53": [10, 11, 15], "5307": 6, "531": 12, "5321": 1, "5331": 1, "5353874e": 15, "536": [1, 6, 7], "537": [1, 7], "538": [1, 7], "5386029e": 15, "53879547e": 11, "539": [1, 7], "54": [10, 12, 13, 15], "540": [1, 7], "541": [1, 7], "542": [1, 7, 10], "5431965589523315": 3, "5440": 1, "54453": 11, "5457": 6, "5478": 1, "5499391e": 15, "54c1e3b9184cb5b6": 11, "55": [1, 10, 15], "55047607421875": 3, "5510": 1, "5517": 1, "5526": 1, "5547451972961426": 3, "5548": 6, "5551414e": 15, "556515": 15, "557": 7, "5577": 1, "558": 7, "5581": 6, "559": 7, "55922699e": 11, "56": [10, 15], "562": [1, 7], "563": [1, 7], "564": [1, 7], "5642787": 13, "5645": 1, "5647": 6, "565": [1, 7], "566": [1, 7], "567": [1, 7], "5671": 1, "5675": 1, "568": [1, 7], "5683": 1, "569": [1, 7], "569000": 8, "57": [1, 9, 10, 15], "5753": [6, 11], "57552516": 15, "576000": 10, "5775": 7, "5786": 1, "5787875e": 15, "5790": 1, "58": [1, 10, 15], "5800208e": 15, "581": 14, "582": [7, 14], "583": 14, "5831212e": 15, "5835": 6, "5872": 6, "5874": 1, "588": 7, "589": 15, "5891": 1, "59": [8, 10, 15], "5903": 1, "5910": 1, "5930856e": 15, "5931": 1, "59453669": 13, "5986011e": 15, "5987856e": 15, "5e": [3, 4, 7], "6": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15], "60": [10, 12, 15], "600": 4, "6004862785339355": 3, "60114670e": 11, "602": 7, "60231": 8, "6041755676269531": 3, "6047": 6, "6093": 6, "61": 15, "6100": [6, 7], "6109": 6, "6130788326263428": 3, "6159": 6, "6194": 1, "62": [7, 10, 15], "6202": 1, "6206": 1, "6209377e": 15, "621": 6, "6230767965316772": 3, "6246": 6, "6261671e": 15, "6298": 1, "63": [4, 7, 15], "6300": 1, "6310": 1, "6391": 12, "6398": 6, "64": [1, 3, 4, 12, 15], "64082434": 13, "640x480": 4, "6413417e": 4, "6413504e": 4, "6435": 11, "6457358e": 15, "6464850902557373": 3, "6496": 1, "65": [13, 15], "6503": 1, "651": 7, "6515": 1, "6525": 6, "6528854370117188": 3, "6549282e": 15, "6565": 1, "6584": 1, "66": [1, 7, 9, 10, 15], "6605": 6, "6621": 6, "6622": 6, "66258": 15, "66265869e": 11, "664000": 8, "6654": 1, "6666715145111084": 3, "6668529e": 15, "6681013e": 15, "67": 15, "6702347e": 15, "6720": 6, "6755": 6, "678": 7, "6783e": 7, "6789": 6, "6796": 6, "68": 15, "680": 7, "6820678e": 4, "6820685e": 4, "68323517e": 11, "6836789846420288": 3, "69": 15, "690": 7, "6922395e": 4, "6922468e": 4, "69412994e": 11, "6th": 8, "7": [3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15], "70": [10, 14, 15], "7003": 1, "7009653": 15, "7014684677124023": 3, "7014991e": 15, "7035142e": 15, "7058": 1, "7070": 1, "7083351": 15, "71": [7, 15], "7112243e": 4, "7112330e": 4, "712508201599121": 3, "7130": 6, "7154": 1, "716": 6, "7179": 1, "72": 15, "7228972911834717": 3, "7267": 6, "7299085e": 15, "73": [7, 15], "7311118841171265": 3, "733": 11, "7349": 6, "7388": 1, "74": 15, "7497": 6, "75": [7, 11, 15], "7500": 7, "7515637874603271": 3, "7530574798583984": 3, "754": 7, "7559e": 7, "7599": 1, "7599962949752808": 3, "76": 15, "762": 7, "765": 12, "768": [3, 6, 7], "769": 12, "77": [1, 4, 15], "7722": 7, "774": 9, "774m": 7, "77519226e": 11, "779": 10, "78": [9, 15], "7843382e": 15, "7848362e": 4, "7848457e": 4, "7860": 6, "7876028e": 15, "789": 1, "7891": 1, "79": [7, 15], "792489528656006": 3, "7939": 1, "7958": 6, "7b": 7, "7b9652b17b68b7a4": 11, "8": [3, 4, 6, 7, 8, 9, 10, 11, 12, 15], "80": [1, 15], "8001447e": 15, "800px": 15, "802": 15, "8023127317428589": 3, "8040": 1, "8048164e": 15, "8053": 1, "8055992e": 15, "8086446e": 15, "81": 15, "8111": 1, "812": 7, "81484222e": 11, "817": 12, "8183104e": 15, "82": 15, "820": 7, "8203": 1, "8210": 1, "8214008808135986": 3, "8291717e": 15, "8296": 1, "8299": 6, "83": [6, 15], "8330071e": 15, "833232": 15, "8336846e": 15, "8399287e": 15, "84": 15, "8418151e": 15, "842": 12, "8424": 1, "8434": 1, "8440": 6, "8440003395080566": 3, "85": [1, 15], "8524": 1, "856": [7, 11], "8573": 1, "85897064e": 11, "86": 15, "8602476e": 15, "8633": 7, "8635560274124146": 3, "864698648452759": 3, "865": [7, 15], "869784951210022": 3, "87": [1, 12, 15], "870": 3, "8719": 6, "872957468032837": 3, "88": [12, 15], "880": 7, "8812459111213684": 3, "88281250e": 11, "8835384e": 15, "88581848e": 11, "8858266472816467": 3, "8888551e": 15, "89": [1, 4, 7, 15], "893": 12, "893294632434845": 3, "8933826684951782": 3, "8993": 1, "8d46a049580037f4": 11, "8e": 11, "8xa100": 7, "9": [1, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15], "90": [4, 7, 12, 15], "9038301706314087": 3, "90570068e": 11, "9069903492927551": 3, "9076787233352661": 3, "9081533e": 15, "9094947576522827": 3, "90m": [8, 9, 10], "91": 15, "9119": 11, "913": 7, "9132639765739441": 3, "914124608039856": 3, "9145498871803284": 3, "9156": 1, "9184016e": 15, "9193634986877441": 3, "91m": [8, 9, 10], "92": 15, "922825038433075": 3, "9231759309768677": 3, "9233587e": 15, "9268": 1, "9298215508460999": 3, "93": 15, "9318363e": 15, "9333570599555969": 3, "9350917935371399": 3, "9375740885734558": 3, "94": [4, 15], "94158": 12, "9419360e": 15, "9422": 1, "9437785e": 15, "9450": 1, "948309600353241": 3, "9484": 6, "9486612677574158": 3, "949081301689148": 3, "9498323202133179": 3, "95": [12, 15], "9506620168685913": 3, "950808048248291": 3, "9508156776428223": 3, "9525609016418457": 3, "9544": 1, "9556533098220825": 3, "96": [4, 15], "9609147310256958": 3, "9616129994392395": 3, "9655719995498657": 3, "9677637219429016": 3, "9686624e": 15, "97": [4, 15], "9711549878120422": 3, "9711923003196716": 3, "9734074473381042": 3, "9736e": 6, "9737": 1, "9741615e": 15, "9762787818908691": 3, "9799185395240784": 3, "98": 15, "9802e": 6, "9804151654243469": 3, "9804179072380066": 3, "98110580444336": 7, "9811086e": 15, "9822817444801331": 3, "9836e": 7, "9846476316452026": 3, "9848976135253906": 3, "985": 7, "9852057695388794": 3, "98758347829183": 7, "99": [7, 12, 15], "9912": 1, "9926449060440063": 3, "9929142e": 4, "9929154e": 4, "9944889545440674": 3, "9951": 7, "9980620e": 15, "9995": 1, "9e15": 4, "A": [3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15], "And": [0, 1, 3, 10], "As": [1, 3, 4, 6, 7, 8, 11, 13], "At": [7, 9], "But": [3, 9, 11, 14], "By": [1, 3, 5, 11], "FOR": 9, "For": [1, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14], "IN": [7, 14], "If": [1, 3, 4, 7, 8, 9, 13, 15], "In": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "Into": 12, "It": [1, 3, 4, 6, 7, 8, 9, 11, 13, 14, 15], "Its": 4, "NOT": [1, 3, 13], "No": [3, 4, 6, 8, 9, 11, 12], "Not": 7, "OF": 9, "ONE": 9, "Of": 13, "On": [4, 9, 10, 13], "One": [1, 4, 5, 9, 11], "THE": 9, "TO": 9, "That": [3, 4, 7], "The": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15], "Then": [1, 3, 7, 9, 13, 14, 15], "There": [4, 7, 8, 9, 11, 12, 13, 15], "These": [1, 4, 5, 7, 9, 15], "To": [1, 4, 5, 7, 9, 10, 11, 14], "With": [4, 7, 11, 12], "_": [1, 3, 4, 6, 7], "_2": 1, "__getitem__": [4, 6, 7], "__init__": [1, 4, 6, 7, 12, 14, 15], "__len__": [4, 6, 7], "__main__": 7, "__name__": [3, 7], "_acc": 4, "_calculate_loss": 4, "_create_model": 4, "_create_test_set": 4, "_default_hp_metr": 4, "_get_tagg": 14, "_kmean": 3, "_loss": 4, "_lrschedul": 4, "_name_or_path": 3, "_pos_tag": 14, "_pytre": 10, "_register_pytree_nod": 10, "_reset_paramet": 4, "_torch_pytre": 10, "a100": 7, "a47": 11, "a_list": 4, "ab": [4, 6], "abat": 11, "abbrevi": 9, "abil": [5, 13], "abl": [7, 11], "about": [1, 4, 6, 7, 8, 10, 11, 12, 13, 15], "abov": [1, 4, 6, 7, 8, 10, 11, 13, 15], "absolut": [3, 6, 11], "abstract": [4, 13], "acc": 4, "acceler": 4, "accelerator_connector": 4, "accept": 11, "access": [1, 3, 4, 13], "accord": [8, 11], "accordingli": 1, "account": 8, "accur": [5, 11, 13, 14], "accuraci": [4, 9], "achiev": [1, 4, 5, 6, 7, 9, 15], "across": [4, 5, 6, 8], "act": [3, 11, 13], "action": 5, "activ": [4, 9, 10, 11], "activation_funct": 3, "actor": 13, "actual": [4, 7, 9, 11], "ad": [1, 3, 4, 7, 8, 9], "adam": [4, 7], "adamw": [3, 7], "adapt": [4, 5, 7], "add": [3, 4, 6, 7, 9, 11, 14], "add_bar": 8, "add_positional_encod": 4, "addit": [4, 6, 7, 9], "addition": [2, 4], "adher": 13, "adj": 3, "adj_list": 3, "adject": [3, 13, 14], "adjust": [4, 5, 6, 7, 11, 12, 15], "administr": 10, "adopt": [5, 6], "advanc": [4, 5, 6, 9, 13], "advantag": [1, 4], "adverb": [3, 13], "aerospac": 12, "affect": 1, "after": [1, 4, 6, 7, 8, 9, 11, 12, 15], "afterward": 4, "ag": [9, 10], "ag_new": 12, "again": [1, 4, 7, 8, 12], "against": [1, 4, 7, 8], "agreement": 13, "ahead": 9, "ai": [4, 8, 11], "aim": [5, 13, 15], "ain": 8, "aiohttp": 10, "aiosign": 10, "aka": [1, 6, 7], "akin": 6, "al": [4, 6], "alammar": 4, "algorithm": [5, 8, 12, 14], "align": [7, 15], "all": [3, 4, 7, 8, 10, 11, 12, 13, 15], "all_context_vec": 1, "all_dataset_label": 12, "all_dataset_text": 12, "allah": 13, "allow": [1, 2, 4, 5, 6, 7], "allowed_speci": 7, "almost": [4, 6, 7, 15], "alon": [1, 7], "aloud": 13, "alpha": 7, "alreadi": [1, 4, 6, 7, 8, 9, 10, 15], "also": [1, 3, 4, 5, 6, 7, 8, 9, 10], "altern": [4, 6, 7, 9], "although": 4, "alwai": [4, 7, 8, 11], "am": [6, 7, 8, 9], "amaz": 9, "ambigu": [9, 13], "american": 8, "among": [4, 5, 7], "amount": [4, 5, 6, 7, 13], "an": [1, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15], "anaconda": [10, 15], "anaconda3": 3, "analysi": [5, 8, 11, 13, 14], "analyt": 8, "analyz": [5, 9, 11, 12, 13], "anatinu": 11, "anc": 11, "anc1": 11, "anchor": 11, "angela": 8, "angl": 4, "ani": [1, 4, 5, 6, 7, 8, 9, 10, 11, 15], "anim": 4, "annot": [3, 5], "anomaly_label": 4, "anomaly_model": 4, "anomaly_result": 4, "anomalypredictor": 4, "anoth": [1, 3, 4, 7, 11, 12, 13], "answer": [3, 5, 9, 13], "anyon": 13, "ap": [7, 11, 13, 15], "ap_model_loc": 14, "ap_russian_model_loc": 14, "apart": [9, 15], "apocalyps": 13, "app": [3, 10], "appdata": [8, 15], "appear": [8, 11, 13], "append": [3, 4, 6, 7, 8, 12, 15], "appli": [3, 4, 6, 7, 9, 10, 14, 15], "applic": [2, 4, 5, 11, 13, 15], "approach": [1, 4, 7, 8, 9, 13, 15], "appropri": [6, 11], "approx": 6, "approxim": [4, 6, 7, 8, 13, 15], "ar": [1, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15], "arang": [4, 6, 7], "arbitrari": [1, 4], "architectur": [1, 2, 3, 15], "area": 11, "aren": [8, 13], "arent": 3, "arg": [11, 12], "argmax": [4, 6, 7, 12], "argsort": 4, "argu": 6, "argument": [4, 7], "aris": 4, "arm": 7, "around": 6, "arrai": [4, 6, 7, 11, 13], "arrang": 13, "art": [2, 7, 9], "articl": [3, 9, 15], "article_list": 3, "artifici": [3, 5, 8, 9, 13, 14], "ascii": 9, "asingularstori": 8, "aspect": 9, "assert": [1, 4, 6, 7], "assess": [5, 13], "assign": [4, 5, 7, 8, 11, 13, 14, 15], "associ": 13, "assum": [4, 6, 7, 11, 13], "astyp": 11, "async": 10, "async_timeout": 10, "att": [6, 7], "attempt": [9, 14], "attend": 4, "attent": [2, 3, 4, 5, 7], "attention_map": 4, "attention_mask": [3, 11], "attention_probs_dropout_prob": 3, "attn": [3, 7], "attn_dropout": 3, "attn_logit": 4, "attn_map": 4, "attn_out": 4, "attn_pdrop": 3, "attn_scor": [1, 6, 7], "attn_score_22": 1, "attn_scores_2": 1, "attn_weight": [1, 6, 7], "attn_weights_2": 1, "attn_weights_2_na": 1, "attn_weights_2_tmp": 1, "attr": 10, "attribut": 13, "augment": 6, "author": [4, 8, 10, 11], "auto": [3, 5, 15], "autom": [5, 13], "automat": [6, 7, 11, 13], "automodelforsequenceclassif": 11, "autoregress": [3, 4, 5], "autotoken": 11, "avail": [4, 5, 7, 8, 11], "avenu": 9, "averag": [4, 7, 8, 12], "averaged_perceptron_tagg": 14, "avg_log_proba": 7, "avg_pool1d": 12, "avoid": 6, "aw": 7, "awai": 7, "awar": 10, "awesom": 15, "ax": [4, 7], "ax1": 7, "ax2": 7, "axi": [4, 7], "b": [1, 6, 7, 11], "b_1": 4, "b_2": 4, "ba": 6, "back": [4, 6, 7, 9, 12], "backbon": 13, "backend": 4, "backward": [3, 6, 7, 12, 15], "bad": 4, "bag": 9, "balanc": 5, "ballpark": 7, "banana": 9, "band": 12, "bar": [4, 6, 7, 8], "bar_width": 7, "bart": 5, "base": [3, 4, 5, 6, 7, 9, 11, 14, 15], "base_lr": 4, "base_url": 4, "basic": [1, 7, 8, 15], "batch": [1, 3, 4, 6, 7, 11, 12], "batch_exampl": 6, "batch_first": 3, "batch_idx": [4, 7], "batch_sampl": 3, "batch_siz": [1, 3, 4, 6, 7, 12], "batchnorm": 4, "bay": 14, "beam": 5, "bear": [3, 12], "beard": 4, "beat": 4, "beauti": 8, "becaus": [1, 4, 7, 8, 9, 11, 13], "becom": [1, 6, 7, 9, 14], "been": [1, 4, 5, 7, 8, 9], "befor": [1, 4, 6, 7, 8, 9, 11], "beforehand": 4, "begin": [4, 6, 7], "beginn": [11, 13, 14], "behavior": [3, 5], "behind": [1, 4, 6, 8, 13], "being": [1, 4, 7, 8], "belong": [4, 11, 15], "below": [1, 4, 6, 7, 8, 9, 11], "benchmark": 4, "benefit": 4, "bert": [4, 5, 9], "bertattent": 3, "bertconfig": 3, "bertembed": 3, "bertencod": 3, "bertformaskedlm": 3, "bertforpretrain": 3, "bertforsequenceclassif": 3, "bertintermedi": 3, "bertlay": 3, "bertlmheadmodel": 3, "bertmodel": 3, "bertoutput": 3, "bertpool": 3, "bertselfattent": 3, "bertselfoutput": 3, "berttoken": 3, "besid": 4, "bessel": 6, "best": [4, 6, 8, 9, 10], "best_model_path": 4, "bet": 12, "better": [1, 4, 5, 6, 8, 9, 13, 15], "between": [1, 3, 4, 6, 7, 8, 10, 13, 14, 15], "beyond": [6, 13], "bi": 9, "bia": [1, 3, 4, 6, 7, 11, 12, 15], "bias": [4, 5, 6], "bidirect": [3, 5], "big": [1, 3, 13], "billion": [5, 9], "bincount": 7, "binxu": 3, "bio": 13, "biotechnologi": 10, "bird": 3, "bit": [1, 4], "bitcoin": 8, "black": [4, 12], "blank": 3, "bloat": 7, "block": [0, 4, 7, 9], "block_arg": 4, "block_siz": [1, 6, 7], "blockport": 8, "blog": 4, "blue": [8, 9], "bm25": 8, "boilerpl": 7, "book": [0, 1, 3, 6, 7, 14], "bool": [1, 6, 7], "boolean": [1, 6, 7, 10], "border": 15, "bore": 14, "bos_token_id": 3, "both": [1, 3, 4, 5, 6, 8, 9, 12, 13, 15], "bound": 11, "bpe": [6, 7], "brain": 10, "brake": 15, "branch": 13, "break": [1, 3, 7, 15], "bridg": 13, "brief": [7, 8], "briefli": 1, "bring": [7, 9], "brought": 15, "brown": 9, "bu": 4, "buffer": 4, "build": [4, 5, 6, 7, 9, 10, 14, 15], "built": 4, "bundl": [0, 9], "byeswickattribut": 6, "byte": 6, "c": [3, 4, 8, 10, 15], "c_attn": [3, 7], "c_fc": [3, 7], "c_proj": [3, 7], "ca": 1, "cach": 10, "cafe": 9, "caf\u00e9": 9, "calc_loss_batch": 7, "calc_loss_load": 7, "calcul": [1, 4, 6, 8, 15], "call": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14], "callback": 4, "came": [4, 9], "can": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "canada": 13, "cancel": 15, "cannot": [4, 15], "capabl": [1, 5, 10], "capac": 5, "captur": [5, 7, 13, 15], "car": 13, "care": [7, 9], "carlyl": 12, "carri": [1, 7], "case": [1, 3, 4, 6, 7, 8, 9], "castellano": 8, "cat": [1, 3, 4, 6, 7, 8, 12, 13], "catalyst": 11, "catbackward0": 1, "categor": 5, "categori": [4, 11, 12, 13, 15], "caus": 4, "causal": [3, 6, 7], "causalattent": 1, "cbow_model": 15, "cbowmodel": 15, "cc": 14, "cdot": [4, 6], "ce": 4, "cell": [1, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15], "center": [6, 15], "certain": [1, 7, 9, 13], "certifi": 10, "cfg": [6, 7], "chanc": [4, 7], "chang": [1, 3, 4, 5, 7, 10, 12], "chapter": [1, 3, 4, 6, 7, 8, 9, 11, 13, 14, 15], "char": 9, "charact": 7, "characterist": [5, 15], "charset": 10, "chatgpt": 13, "cheap": 7, "cheaper": 6, "check": [0, 1, 4, 6, 7, 11], "checkpoint": [3, 4, 7, 11], "checkpoint_callback": 4, "checkpoint_path": 4, "child": 3, "china": 13, "chocol": 7, "choic": [3, 4, 5, 13, 15], "choos": [1, 6], "chop": 9, "chose": 11, "chosen": [4, 15], "chri": 10, "chuck": 3, "chunk": [4, 6, 7], "cifar": 4, "cifar10": 4, "cifar100": 4, "circumst": 5, "citi": 13, "cividi": 4, "ckpt": [4, 7], "cl": [1, 3, 4, 7, 12], "claim": 13, "class": [4, 6, 7, 11, 12, 14, 15], "classic": [3, 4], "classif": [4, 5, 10, 14, 15], "classifi": [4, 11, 14, 15], "classification_report": 10, "classifier_dropout": 3, "claus": 3, "claw": 12, "clean": 14, "clearli": 4, "clf": 13, "click": [8, 9], "clip": [4, 11], "clip_grad_norm_": 4, "close": [4, 6, 7, 9, 13, 15], "closer": [4, 7], "cloud": [7, 12], "cls_index": 3, "cluster": [3, 13], "cluster_word": 3, "clutter": 1, "cmap": 4, "cnn": 4, "co": [3, 4, 7, 8, 10, 11, 13, 15], "coars": 4, "coat": 11, "code": [0, 2, 4, 7, 9, 10, 12, 15], "coher": [5, 7, 13], "colab": [4, 9, 10], "collate_fn": 12, "collect": [8, 9, 10, 13], "color": 4, "colorbar": [3, 4], "column": [4, 6, 10, 11], "com": [4, 7, 8, 10, 11, 13, 15], "combat": 9, "combin": [1, 4, 5, 6, 7, 13, 14], "come": [1, 4, 9, 11, 12], "comment": [11, 12], "commerci": 12, "common": [1, 3, 4, 6, 7, 8, 9, 11, 13], "commonli": [1, 4, 6, 8, 9, 14], "commun": [4, 8, 13], "communi": 8, "compact": 7, "compar": [1, 4, 6, 11], "compat": 6, "complet": [4, 5, 11, 13, 14], "complex": [1, 3, 4, 5, 6, 9, 13], "complic": 1, "compon": [5, 11], "compos": [4, 8, 13], "composit": 11, "comprehend": 5, "comprehens": [5, 13], "compris": 5, "compulsori": 9, "comput": [3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15], "computation": [6, 7, 9], "concat": 10, "concaten": [1, 4, 8, 10, 11], "concept": [6, 7, 9], "conceptu": [1, 3], "concern": [5, 13], "concis": 11, "conclud": 4, "conclus": 8, "concret": 1, "condens": 1, "condit": [3, 5, 7], "confid": 7, "config": 3, "configur": [3, 6, 7, 9, 11], "configure_optim": 4, "conform": 5, "confus": 4, "confusion_matrix": 10, "confusionmatrixdisplai": 10, "conj": 3, "conjunct": [3, 13], "conjunction_list": 3, "connect": [4, 7, 12, 13], "consecut": 4, "consequ": 3, "consid": [1, 4, 6, 7, 8, 9, 11, 13, 14, 15], "consider": [5, 9], "consist": [1, 4, 5, 7, 9, 13, 15], "constitut": 4, "construct": 12, "contact": 4, "contain": [1, 4, 5, 7, 8, 9, 10, 12, 13, 15], "content": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "context": [1, 3, 5, 6, 7, 11, 13, 14, 15], "context_emb": 15, "context_len": 7, "context_s": [6, 7, 15], "context_vec": [1, 6, 7], "context_vec_2": 1, "contextu": 5, "contigu": [1, 6], "continu": [1, 3, 4, 7, 13], "contradict": 13, "contrast": 4, "contribut": [1, 8, 13], "control": [3, 15], "controversi": 12, "conv1d": 3, "convei": 9, "conveni": [1, 7], "convent": [1, 6, 7], "converg": 6, "convers": 13, "convert": [1, 6, 7, 8, 11, 12, 14, 15], "convinc": 4, "convolut": 15, "copi": 7, "core": [4, 13, 15], "corefer": 13, "cornerston": 2, "corona": 10, "coronaviru": 10, "corpora": [8, 9], "corpu": [5, 7, 9, 10, 12, 14, 15], "corpus_embed": 10, "corpus_nam": 8, "correct": [3, 4, 6, 7, 9, 13], "correct_cnt": 12, "correctli": [1, 4, 7, 9], "correl": 4, "correspond": [4, 6, 7, 12, 13, 14], "correspondingli": 6, "cosin": [4, 11], "cosinewarmup": 4, "cosinewarmupschedul": 4, "cost": 7, "could": [4, 8, 11], "couldn": 8, "count": [5, 6, 8, 11, 12, 13], "count_vector": 13, "counter": 8, "countvector": [9, 13], "coupl": 11, "cours": [1, 3, 4, 6, 7, 11, 13], "cover": [1, 6, 7, 9, 12], "cow": 3, "cp39": [9, 10], "cpu": [3, 4, 7, 12, 15], "crabtre": 13, "craft": 3, "crash": 13, "creat": [1, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15], "create_dataloader_v1": [6, 7], "credit": 4, "criterion": [12, 15], "crop": [6, 7], "cross": [4, 13], "cross_entropi": [4, 7], "cross_val_scor": 13, "crossentropyloss": [12, 15], "crucial": [1, 4, 5, 7, 13, 15], "crude": [9, 12], "cs231n": 15, "csv": [8, 10, 11, 13], "ctx_len": [6, 7], "cu": 10, "cu12": 10, "cubla": 10, "cuda": [3, 4, 7, 10, 12], "cuda_visible_devic": 4, "cudnn": [4, 10], "cufft": 10, "culliton": 13, "cultur": 13, "cumul": [5, 6, 12], "cupti": 10, "curand": 10, "current": [1, 4, 6, 7, 11, 14, 15], "cusolv": 10, "cuspars": 10, "cust": 8, "custom": [9, 13], "cv": 13, "cynic": 12, "d": [1, 3, 6, 7, 8, 10, 11, 12, 15], "d1": 8, "d2": 8, "d3": 8, "d_": 4, "d_in": [1, 6, 7], "d_k": [1, 4], "d_model": 4, "d_out": [1, 6, 7], "dai": [6, 7, 9, 11], "danc": 3, "data": [4, 5, 6, 8, 9, 10, 11, 14, 15], "data_input": 4, "data_load": [4, 7], "data_mean": 4, "data_std": 4, "databas": [8, 13], "datacollatorforlanguagemodel": 3, "datafram": 8, "dataload": [4, 6, 7, 12], "dataset": [4, 5, 6, 7, 8, 9, 11, 13, 14, 15], "dataset_path": 4, "datasetdict": 11, "date": [7, 8, 13, 15], "dateutil": [10, 15], "dattaset": 12, "dd": 11, "de": 3, "deal": [4, 9, 13, 14], "deberta": 11, "debertav2forsequenceclassif": 11, "decai": [4, 11], "decid": 6, "decis": 5, "decod": [1, 3, 4, 5, 6, 9], "decode2sent": 3, "decode2word": 3, "decoded_text": [6, 7], "decreas": [4, 7], "deed": 13, "deep": [4, 5, 6, 7, 9, 11, 13], "deepai": 4, "deepest": 3, "deepli": 13, "def": [1, 3, 4, 6, 7, 8, 9, 11, 12, 14, 15], "default": [3, 4, 10], "default_root_dir": 4, "defens": 12, "defin": [1, 4, 5, 6, 7, 9, 13, 15], "definit": [9, 13], "degrad": 10, "degre": 7, "delv": [2, 13], "demand": 7, "demo": 15, "demonstr": [1, 5], "denomin": 6, "dens": [3, 4, 11, 15], "depart": 13, "depend": [4, 5, 11, 13, 14, 15], "depict": [1, 6], "deploy": 5, "deprec": 10, "depth": [3, 12], "deriv": [1, 13], "describ": [1, 4, 5, 8, 11, 13], "descript": [12, 13, 14], "design": [1, 3, 4, 5], "desir": [1, 4, 5, 6, 7], "despit": [4, 13], "detach": [3, 4, 15], "detail": [4, 6, 9, 10, 11], "detect": 14, "determin": [1, 4, 5, 6, 7, 12, 13], "determinist": 4, "develop": [1, 3, 5, 10, 13, 15], "deviat": 6, "devic": [3, 4, 6, 7, 10, 11, 12], "df": [10, 11], "df_articl": [8, 10], "diagon": [1, 6, 7], "dialog": 13, "dict": 4, "dict_kei": 7, "dictionari": [3, 7, 9, 11], "did": 8, "didn": [6, 8], "differ": [3, 4, 5, 6, 7, 8, 9, 11, 13], "difficulti": 4, "digit": [11, 13], "dill": 10, "dim": [1, 3, 4, 6, 7, 12, 15], "dim_feedforward": 4, "dimens": [1, 4, 6, 7, 10, 12, 15], "dimension": [1, 4, 6, 7, 15], "dine": 13, "directli": [4, 5, 6, 11, 13], "disabl": [1, 6, 7, 10], "disambigu": 13, "disast": 13, "disaster_tweets_test": 13, "disaster_tweets_train": 13, "discount": 13, "discoveri": 11, "discret": [4, 15], "discuss": [4, 6, 7], "disk": [4, 10], "displai": 15, "disrupt": 1, "dist": [1, 7], "distanc": 15, "distinct": 12, "distinguish": [4, 10, 13, 15], "distribut": [1, 4, 6, 7, 8, 12, 15], "distribution_nam": [1, 7], "div_term": 4, "divbackward0": [1, 6], "diverg": 4, "divers": [5, 7], "divid": [1, 6, 7, 8], "divis": [1, 6, 7], "dl": 4, "do": [4, 6, 7, 8, 9, 11, 13, 14], "do_sampl": 3, "doc": [3, 10], "document": [4, 11], "doe": [1, 4, 6, 7, 8, 9, 10, 13], "doesn": [1, 4, 8], "dog": [3, 8, 9], "doldrum": 12, "dollar": 7, "domain": [4, 5, 7, 9, 13], "don": [1, 3, 4, 6, 7, 8, 9, 12], "done": [1, 4, 8, 9, 11, 14], "donkei": 7, "dot": [1, 4, 6, 7], "doubl": 6, "down": [4, 7, 8, 9, 11], "download": [4, 7, 8, 14, 15], "download_and_load_gpt2": 7, "downstream": 3, "dramat": 11, "dream": 10, "drop": [1, 3, 6], "drop_emb": [6, 7], "drop_last": [4, 6, 7], "drop_rat": [6, 7], "drop_resid": [6, 7], "dropout": [3, 4, 6, 7], "dt": 14, "dtype": [3, 4, 12], "due": [1, 6, 7, 9, 13], "dummygptmodel": 6, "dummylayernorm": 6, "dummytransformerblock": 6, "duplic": [1, 10], "dure": [1, 2, 4, 5, 6, 7, 8, 11, 12, 15], "dwindl": 12, "dynam": [4, 5], "e": [0, 1, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14], "each": [1, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15], "earli": 6, "earlier": [1, 7, 9, 11], "earn": 12, "earthquak": 13, "easi": 9, "easier": [4, 6, 7, 9, 13, 14], "easili": [4, 9], "eat": 13, "economi": 12, "educ": 7, "effect": [1, 4, 5, 6, 7, 9, 12, 13, 15], "effici": [1, 4, 5, 10], "effort": [6, 7], "eg": 15, "either": [10, 13, 15], "elabor": 3, "elbow": 7, "electra": 5, "element": [1, 4, 5, 6, 12, 13], "elementari": 9, "elementwise_affin": 3, "elimin": 11, "elonmusk": 9, "els": [1, 3, 4, 6, 7, 12, 14], "email": 11, "emb": [4, 10], "emb_dim": [6, 7], "emb_siz": [6, 7], "embd_pdrop": 3, "embed": [1, 3, 4, 5, 6, 7, 9, 12, 13], "embed_dim": [4, 12], "embed_s": 15, "embedd": 10, "emerg": 3, "emphas": 5, "emploi": 9, "empow": 13, "empti": [1, 4], "en": 10, "enabl": [1, 4, 5, 6, 7, 10, 13], "encod": [1, 3, 5, 6, 7, 9, 10], "encod_block": 4, "encode2indic": 3, "encode_sent": 3, "encoded_tensor": [6, 7], "encoderblock": 4, "encompass": 5, "end": [1, 3, 4, 7, 8, 9, 12, 15], "endoftext": 7, "eng": 14, "engag": 1, "engin": [1, 8], "english": [3, 8, 9, 11, 13, 14], "english_stopword": 8, "enhanc": [1, 5], "enjoi": 14, "enough": [4, 7, 9], "ensur": [1, 4, 7, 13], "entail": 13, "enter": [1, 4], "enthusiast": 9, "entir": [1, 6, 7, 9, 11, 12, 13], "entiti": 9, "entri": [6, 7, 12, 13], "entropi": 4, "entropy_loss": 7, "enumer": [1, 3, 4, 6, 7, 12, 15], "env": 3, "envelop": 7, "environ": [4, 5, 10, 11, 13], "eos_id": 3, "eos_token_id": 3, "ep": [3, 6, 7], "epoch": [3, 4, 7, 11, 12, 15], "epochs_seen": 7, "epochs_tensor": 7, "equal": [3, 4, 7], "equip": 5, "equival": 1, "equivari": 4, "error": [4, 5, 6, 13], "eshan": 10, "especi": [4, 5, 9], "essai": 4, "essenti": [1, 5, 13], "estim": [4, 6], "et": [4, 6], "eta": [8, 9, 10], "etc": [4, 9, 13, 15], "etern": 3, "ethereum": 8, "ethic": 5, "eval": [3, 4, 6, 7], "eval_d": 11, "eval_dataset": 11, "eval_df": 11, "eval_freq": 7, "eval_it": 7, "evalu": [8, 11, 13], "evaluate_model": 7, "evaluation_strategi": 11, "even": [4, 5, 6, 7, 9, 15], "everi": [1, 4, 5, 6, 7, 8, 9, 11, 15], "everyth": 9, "evid": [9, 13], "evolutionari": 5, "ex": 9, "exact": [4, 6], "exactli": [3, 4, 9], "examin": 3, "exampl": [1, 3, 4, 5, 6, 7, 9, 11, 13, 15], "example_train_vector": 13, "exampledeepneuralnetwork": 6, "exce": [6, 7], "excel": 5, "except": [4, 7], "execut": [1, 4, 7, 9, 13, 14, 15], "exercis": 6, "exist": [4, 7, 11, 13, 14], "exist_ok": 4, "exp": [1, 4, 7], "expand": [3, 9], "expand_mask": 4, "expect": [3, 4, 7, 8, 11, 12], "expens": 7, "experi": [5, 9], "expert": 13, "explain": [1, 4, 7], "explan": [4, 11], "explicitli": [3, 6], "explor": [2, 4, 5, 9, 11, 15], "exponenti": [4, 7], "export": 4, "express": [4, 8, 9], "extend": 3, "extens": [5, 10], "extent": [4, 9], "extermin": 7, "extra": 4, "extract": [3, 4, 8, 9, 13, 14], "extract_featur": [4, 14], "extracted_featur": 4, "extrem": [1, 4], "ey": 3, "f": [3, 4, 6, 7, 10, 12, 14, 15], "f1": [10, 13], "fabiochiu": [8, 10], "face": [4, 7, 8, 10, 11, 13], "facilit": 5, "fact": [4, 7], "facto": 3, "factor": [1, 4, 9], "fail": 4, "fairli": 9, "faith": 3, "fall": [13, 15], "fals": [1, 3, 4, 6, 7, 8, 10, 12, 13], "fame": 15, "famili": [3, 4, 15], "familiar": 3, "famou": 15, "fan": 10, "fanci": 7, "far": [3, 7, 15], "fashion": 3, "fast": [6, 7, 11], "faster": [4, 6, 8, 11, 15], "fat": 3, "fc": [4, 12], "feasibl": [1, 9], "feat": 4, "featur": [4, 5, 6, 8, 11, 13, 14], "feature_extract": 13, "feature_set": 14, "featureiman": 6, "fed": 3, "feed": [4, 7], "feedback": 5, "feedforward": [5, 6, 7, 15], "feel": [0, 3, 4, 7, 9], "fellow": 7, "felt": 7, "fetch": 4, "few": [3, 4, 7, 8, 9], "ff": [6, 7], "ffn": [4, 6], "field": [2, 4, 9, 14], "fig": [4, 7, 8], "fig_siz": 4, "figsiz": [3, 4, 6, 7], "figur": [1, 3, 4, 6, 7], "file": [1, 4, 7, 9, 10, 14], "file_download": 10, "file_id": 8, "file_nam": 4, "file_path": [4, 7], "file_url": 4, "fileid": 8, "filelock": 10, "filenam": [8, 10], "fill": [1, 3, 4, 6, 7, 13], "fill_": 4, "film": 9, "filter": [7, 9, 13, 14], "filtered_token": [9, 14], "filterwarn": 11, "final": [3, 4, 5, 6, 7, 11, 14], "final_norm": [6, 7], "find": [4, 7, 9, 14], "fine": [3, 4, 5, 9], "finetun": [3, 4, 7], "finish": [4, 7, 11], "finit": 5, "fire": 13, "firm": 12, "first": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "first_head": 1, "first_r": 1, "firstli": 4, "fit": [1, 3, 4, 5, 13], "fit_on_text": 12, "fit_transform": [3, 13], "five": 13, "fix": [3, 4, 11], "flag": 4, "flat": 7, "flatten": 7, "flew": 3, "flip": 4, "float": [4, 7, 11], "float32": 6, "flour": 4, "flow": [4, 6, 13], "fly": 3, "focu": [2, 4, 5, 6, 7], "focus": [4, 13], "folder": [4, 7], "folk": 11, "follow": [1, 3, 4, 5, 6, 7, 9, 11, 13], "fontsiz": [3, 4], "forest": [11, 13], "forgiv": 13, "form": [4, 5, 7, 9, 12, 13, 14], "format": [7, 12], "formul": 8, "formula": 6, "forth": 1, "fortun": 7, "forward": [1, 4, 7, 12, 13, 15], "found": [1, 4, 6, 14], "foundat": [2, 5], "four": [4, 12], "fox": [3, 4, 9], "fp16": 11, "frac": [4, 6], "frame": 15, "framework": 1, "free": [3, 4, 7, 9], "freez": 13, "freq": [7, 11], "frequenc": [4, 15], "frequent": [8, 15], "friendli": 13, "from": [1, 2, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15], "from_nam": [1, 7], "from_numpi": 4, "from_panda": 11, "from_pretrain": [3, 11], "from_text_to_count": 8, "frozenlist": 10, "fruit": 13, "fsspec": 10, "fst": 15, "fu": 8, "full": [3, 4], "full_text": [8, 10], "full_text_low": 8, "full_text_no_punctu": 8, "full_text_token": 8, "full_word_set": 3, "fulli": [1, 4, 12], "fully_expand": 3, "function": [1, 4, 5, 6, 8, 9, 10, 11, 14, 15], "functool": 4, "fundament": [2, 5, 9], "further": [1, 4, 5, 8, 9, 14, 15], "furthermor": 1, "futur": [8, 13], "futurewarn": 3, "fuzzytm": 15, "g": [3, 4, 6, 7, 11, 13, 14], "gage": 10, "gamma": 12, "gap": 13, "gate": 6, "gather": 15, "gaussian": 6, "gdrive": 4, "geeksforgeek": 15, "gees": [9, 13], "gelu": [3, 7], "gelu_new": 3, "geluactiv": 3, "gener": [2, 4, 5, 10, 11, 15], "generate_and_print_sampl": 7, "generate_sent": 3, "generate_simpl": 7, "generate_text": 6, "generate_text_simpl": [6, 7], "geniu": 7, "gensim": 15, "get": [1, 4, 6, 7, 8, 9, 10, 13, 14, 15], "get_attention_map": 4, "get_encod": [6, 7], "get_ipython": 8, "get_lr": 4, "get_lr_factor": 4, "get_vocab": 11, "ghosh": 8, "ghoshratul063": 8, "gigaword": 15, "gimpel": 6, "giraff": 3, "gisburn": 7, "github": [4, 7, 13, 15], "githubusercont": 4, "give": [0, 1, 4, 8, 9], "given": [1, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15], "glanc": 1, "glass": 4, "global": 15, "global_step": 7, "glossari": 4, "glove": 9, "glove_model": 15, "go": [4, 8, 9, 12, 14], "goal": [1, 7], "god": 3, "goe": 4, "good": [1, 3, 4, 7, 9, 10, 13, 15], "googl": [4, 8, 10, 14, 15], "googlecolab": 4, "googledr": 4, "goos": 9, "got": 4, "gpe": 14, "gpt": [1, 2, 5, 9], "gpt2": [6, 7], "gpt2attent": 3, "gpt2block": 3, "gpt2config": 3, "gpt2lmheadmodel": 3, "gpt2mlp": 3, "gpt2model": 3, "gpt2token": 3, "gpt_config_124m": [6, 7], "gpt_download": 7, "gptconfig": 3, "gptdatasetv1": [6, 7], "gptlmmodel": 3, "gptmodel": [6, 7], "gpttoken": 3, "gpu": [4, 7, 12], "grad": 6, "grad_fn": [1, 6], "gradient": [1, 4, 6, 7, 12], "gradient_checkpoint": 3, "gradient_clip_v": 4, "gradual": [4, 5], "grain": 4, "gram": 9, "grammar": [9, 13], "grammat": [1, 3, 5, 7, 13], "graph": [4, 15], "grasp": [5, 9], "great": [4, 13], "greater": 7, "greedi": 6, "greek": 1, "green": 12, "grid": 6, "group": [4, 9, 12], "guid": [5, 10, 14], "gutenberg": 8, "h": [3, 4], "h01": 11, "ha": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "had": [4, 7, 8, 9], "hadn": 8, "half": [1, 8, 15], "hamper": 9, "hand": [1, 3, 4, 14, 15], "handcraft": 3, "handl": [1, 5], "hang": 12, "happen": [1, 7, 13], "har": 5, "hard": [3, 4], "harder": 4, "hardwar": [5, 7], "harsh": 4, "hasn": 8, "have": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15], "haven": [8, 10], "he": [7, 8], "head": [4, 6, 7, 8, 10, 11, 13], "head_dim": [1, 4, 6, 7], "health": 10, "heard": [3, 10, 13], "height": 15, "hello": [3, 6, 7], "help": [4, 5, 6, 9, 13, 14, 15], "henc": [1, 4], "hendryck": 6, "henetflix": 7, "her": 8, "here": [0, 1, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14], "herself": 8, "heurist": 9, "hf_hub_disable_symlinks_warn": 10, "hf_hub_download": [8, 10], "hi": [7, 8, 9], "hidden": [1, 4, 6, 15], "hidden_act": 3, "hidden_dropout_prob": 3, "hidden_s": 3, "hiddendim": 4, "high": [4, 8, 15], "higher": [4, 7, 8, 15], "highest": [4, 6, 7], "highli": 1, "highlight": [1, 5, 13], "him": [7, 8, 10], "himself": 8, "hold": [1, 6, 8], "home": [9, 14], "homophon": 15, "hope": 9, "hors": 3, "hostedtoolcach": [1, 7, 8, 9, 10, 14], "hot": [4, 6, 15], "hotfix": 10, "hour": 7, "hourli": 7, "how": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15], "howard": 11, "howev": [1, 4, 6, 7, 8, 9], "hparam": [4, 7], "href": 15, "hspace": 4, "html": [13, 14, 15], "http": [3, 4, 7, 8, 10, 11, 13, 14, 15], "httperror": 4, "hub": [8, 10], "hug": [8, 10, 11], "huge": 9, "huggingfac": [3, 4, 8, 10], "huggingface_hub": [8, 10], "human": [3, 5, 9, 13, 14], "hundr": 7, "hype": 4, "hyperparamet": [4, 11, 15], "hypothesi": 13, "i": [0, 1, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15], "i1109": 4, "iclust": 3, "id": [3, 7, 11, 13], "idea": [1, 4, 6, 11, 13, 15], "ideal": [4, 7, 13], "ident": [3, 4, 11], "identif": 11, "identifi": [4, 13, 14], "idf": 9, "idiom": 13, "idna": 10, "idx": [1, 4, 6, 7], "idx_cond": [6, 7], "idx_next": [6, 7], "ifram": 15, "ignor": [3, 4, 9, 11, 15], "ill": 10, "illustr": [1, 4, 6, 7, 14], "imag": [0, 4, 7, 8, 13, 14, 15], "imagenet": 4, "imagenet1k_v1": 4, "imagin": 4, "imbal": 4, "img": 4, "img_dim": 4, "img_feat": 4, "img_grid": 4, "img_idx_by_label": 4, "img_indic": 4, "img_set": 4, "immedi": 14, "impact": [4, 5, 9], "implement": [4, 7, 8, 14], "impli": [1, 13], "implicit": 5, "implicitli": [1, 6, 7], "import": [1, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15], "importantli": 4, "importlib": [1, 6, 7], "impress": 5, "improv": [4, 5, 6, 11], "imshow": [3, 4], "in_featur": 3, "in_idx": [6, 7], "inbound": 11, "inch": 7, "includ": [1, 4, 5, 6, 7, 9, 11, 13, 14, 15], "incomprehens": 7, "inconsist": 1, "incorpor": [1, 5, 6], "incorrect": 3, "increas": [4, 7, 9], "incred": 4, "ind": 3, "ind_seq": 3, "ind_tsr": 3, "inde": [1, 4, 8], "independ": [6, 14], "index": [1, 4, 6, 7, 12], "index_word": 12, "india": 15, "indian": 15, "indic": [3, 4, 5, 6, 7, 10, 13, 14], "indistinguish": 13, "individu": [1, 5, 13, 14], "induc": 9, "industri": [5, 9, 12], "ineffici": 4, "inf": [1, 6, 7], "infer": [1, 5, 7, 11, 13], "infin": 1, "influenc": 5, "inform": [1, 4, 8, 9, 14, 15], "ingest": 9, "inher": 13, "inherit": 4, "init": 4, "init_weight": 12, "initi": [1, 3, 4, 5, 6, 7, 11, 12, 15], "initial_token": 3, "initializer_rang": 3, "initrang": 12, "inlin": 4, "inner": 4, "inp_data": 4, "inplac": [3, 4], "input": [2, 3, 4, 5, 6, 7, 9, 11, 13, 14, 15], "input_batch": 7, "input_chunk": [6, 7], "input_data": 4, "input_dim": 4, "input_dropout": 4, "input_id": [3, 6, 7, 11], "input_net": 4, "insens": 7, "insid": [1, 4, 7, 12], "inspir": [1, 3, 4, 6, 7, 8, 9, 11, 13, 14, 15], "instabl": 1, "instal": [4, 7, 8, 9, 13, 14, 15], "instanc": [1, 4, 7, 8, 11], "instanti": [6, 12], "instead": [1, 4, 6, 7, 9, 10], "instruct": 3, "int": [7, 12], "int32": 12, "integr": 1, "intellig": [5, 8, 9, 13, 14], "intend": [4, 5, 13], "intens": [5, 6, 9, 15], "intent": 13, "inter": 12, "interact": [5, 8, 13, 14], "intercept": 12, "interest": [1, 4], "interfac": 6, "intermedi": [1, 3], "intermediate_act_fn": 3, "intermediate_s": 3, "intern": 7, "internet": 8, "interpret": [1, 4, 7, 13], "intertwin": 13, "interv": 4, "intrans_verb_list": 3, "intransit": 3, "intric": 5, "introduc": [1, 2, 3, 7], "introduct": 1, "intuit": [1, 4, 8], "inu": 11, "invari": 4, "inventori": 13, "inverse_dictionari": 3, "inverse_vocab": 7, "invest": 12, "invis": [7, 10], "involv": [1, 5, 9, 13], "io": 15, "ipython": [13, 14, 15], "ironi": [7, 13], "is_avail": [3, 4, 7, 12], "is_data_sci": 10, "isdir": 12, "isfil": 4, "isinst": 3, "isn": [1, 8], "issu": [1, 4], "item": [3, 4, 6, 7, 8, 11, 12, 15], "iter": [4, 5, 6, 7, 11, 15], "its": [4, 5, 6, 7, 8, 9, 12, 13, 14, 15], "itself": [1, 4, 7, 8], "iv": 3, "j": [1, 3], "jack": 7, "jai": 4, "jakob": 4, "jargon": 9, "jeremi": 11, "jinja2": 10, "jj": 14, "joblib": [9, 10], "john": 14, "join": [3, 4, 8, 9], "jointli": 1, "josh": 10, "journei": 1, "json": [4, 7], "jump": [3, 14], "june": 8, "jupyt": [3, 13], "jupyterlab_myst": [13, 14, 15], "just": [6, 7, 8, 9, 10, 11, 13], "k": [1, 4, 6], "k_b": 7, "k_w": 7, "kaiser": 4, "karim": 4, "kb": [8, 9, 10], "keep": [3, 7, 8, 10], "keepdim": [1, 6, 7], "kei": [1, 3, 4, 5, 6, 7, 12], "kept": 13, "kera": [9, 12], "keras_preprocess": 12, "kernel": [8, 10], "kernel_s": 12, "key_2": 1, "keyedvector": 15, "keys_2": 1, "keyword": 8, "kill": 13, "kind": [1, 3, 7, 13], "kmean": 3, "kmeans2": 3, "know": [3, 4, 7], "known": [1, 3, 4, 6, 8, 9, 13], "kwarg": 4, "l": 4, "l2": 11, "l6": 10, "la": 13, "label": [3, 4, 5, 6, 7, 8, 11, 12, 13, 14], "label1": 12, "label2": 12, "labeln": 12, "labels": 4, "labels_": 3, "lambda": 10, "lang": 14, "langua": 13, "languag": [1, 4, 6, 7, 8, 9, 11, 14, 15], "laptop": 7, "larg": [1, 4, 6, 7, 9, 11, 13, 15], "larger": [4, 5, 6, 8, 15], "largest": 7, "last": [1, 3, 4, 6, 7, 8, 9, 11, 12, 14], "last_epoch": 4, "lastli": [6, 7], "late": 9, "later": [1, 4, 6, 7, 9, 12], "laugh": 7, "law": 5, "layer": [3, 4, 5, 7, 12, 15], "layer_norm_ep": 3, "layer_norm_epsilon": 3, "layer_output": 6, "layer_s": 6, "layernorm": [3, 4, 6, 7], "layout": 7, "lazi": 9, "lead": [1, 4, 5], "learn": [1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "learner": 6, "learning_r": [11, 15], "learningratemonitor": 4, "least": 4, "leav": 13, "left": [4, 6, 7], "legal": 11, "legend": 7, "lement": 4, "lemma": 14, "lemmatized_token": [9, 14], "len": [3, 4, 6, 7, 8, 12, 15], "length": [3, 4, 6, 7, 8, 12], "less": 7, "lesson": 8, "let": [1, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15], "letter": [1, 12], "level": [3, 4, 9, 13], "leverag": [5, 10, 15], "lexic": 13, "lib": [1, 3, 7, 8, 9, 10, 14, 15], "librari": [3, 4, 7, 8, 9, 13, 14], "lichter": 8, "life": [3, 10], "light": [12, 13], "lightningmodul": 4, "like": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "likelihood": 5, "lilian": 4, "limit": [3, 10, 15], "line": [1, 3, 4, 6, 7, 8, 9, 11, 12, 14], "linear": [1, 3, 4, 7, 12, 13, 15], "linear_model": [10, 13], "linear_net": 4, "linear_out": 4, "linestyl": 7, "linewidth": 4, "linguist": [8, 13], "link": 13, "linspac": [6, 7], "lipp": 4, "list": [3, 4, 6, 7, 8, 9, 12, 14], "lister": 12, "liter": [12, 13], "littl": [4, 7], "liu": 4, "live": [3, 10, 13], "ll": [6, 8, 11, 13, 15], "llama": [5, 6, 7], "llm": [1, 3], "lm_head": 3, "ln": 6, "ln_1": [3, 7], "ln_2": [3, 7], "ln_f": 3, "load": [4, 6, 9, 11, 13, 14, 15], "load_data_path": 12, "load_from_checkpoint": 4, "load_state_dict": 7, "load_weights_into_gpt": 7, "loaded_model": 15, "loader": [1, 4, 7], "loc": 7, "local": [4, 8, 14], "local_rank": 4, "locat": [12, 13, 14], "log": [4, 7, 8, 11], "log_proba": 7, "logarithm": [7, 8], "logger": 4, "logist": 10, "logisticregress": 10, "logit": [4, 6, 7], "logits_flat": 7, "long": [3, 4, 5, 6], "longest": 3, "longtensor": 4, "look": [1, 3, 4, 6, 7, 8, 9, 11, 12, 13], "lookuperror": 14, "loop": [3, 7, 15], "loss": [3, 4, 6, 11, 12, 15], "loss_curv": 3, "lost": 4, "lot": [4, 9], "love": [3, 8, 13], "low": [4, 8], "lower": [1, 4, 7, 8, 9, 12, 14, 15], "lowercas": [8, 12, 15], "lr": [3, 4, 7, 11, 12, 15], "lr_factor": 4, "lr_schedul": [4, 12], "lr_scheduler_typ": 11, "luck": 10, "m": [4, 8, 11, 13, 14, 15], "ma": 8, "machin": [1, 3, 4, 7, 8, 9, 10, 11, 13, 14], "made": 4, "magnitud": 4, "mai": [1, 3, 5, 8, 9, 10, 13, 14], "main": [1, 4, 7, 13, 15], "mainli": [4, 6, 7, 15], "maintain": 3, "major": [1, 3, 4, 6, 7, 8, 9, 11, 13, 14, 15], "make": [1, 3, 4, 5, 7, 8, 9, 12, 13, 14], "make_grid": 4, "makedir": 4, "maketran": [9, 12], "male": 4, "manag": 13, "mani": [2, 3, 4, 5, 6, 7, 8, 9, 15], "manifold": 3, "manner": [4, 9], "manual": [1, 7], "manual_se": [1, 6, 7], "manylinux1_x86_64": 10, "manylinux2014_x86_64": [9, 10], "manylinux_2_17_x86_64": [9, 10], "manylinux_2_28_x86_64": 10, "manylinux_2_5_x86_64": 10, "map": [4, 11, 12, 15], "marker": [3, 4], "markeredgecolor": 4, "markers": 4, "market": [8, 12], "markupsaf": 10, "mask": [3, 4, 6, 7], "mask_bool": [1, 6, 7], "mask_simpl": 1, "masked_fil": [1, 4], "masked_fill_": [1, 6, 7], "masked_simpl": 1, "masked_simple_norm": 1, "maskedfillbackward0": 1, "massiv": [5, 9], "masterclass": 4, "mat": [8, 13], "match": [1, 6, 7, 11], "math": 4, "mathemat": 7, "matmul": 4, "matplotlib": [3, 4, 6, 7, 13, 14, 15], "matric": [1, 4, 6, 7], "matrix": [1, 4, 6, 7, 15], "matt": 13, "matter": [3, 4], "max": 4, "max_depth": 3, "max_epoch": 4, "max_it": 4, "max_len": [3, 4], "max_length": [3, 6, 7], "max_new_token": [6, 7], "max_num_it": 4, "max_position_embed": 3, "maxim": [5, 7], "maximum": [4, 6, 15], "mayb": 8, "mb": [6, 8, 9, 10], "mc": 0, "me": [7, 8], "mean": [1, 3, 4, 6, 7, 9, 11, 12, 13, 14, 15], "meanbackward1": 6, "meaning": [9, 13, 15], "meanwhil": 4, "measur": [7, 8], "mechan": [2, 3, 4, 5, 6], "medium": [6, 7, 15], "medium_articl": [8, 10], "megabyt": 6, "member": 3, "memor": 7, "memori": [4, 6, 15], "mental": 10, "mention": [8, 13], "messag": [10, 13], "meta": 7, "metadata": [1, 6, 7, 8, 9, 10], "method": [4, 5, 6, 7, 9, 13, 14, 15], "methodologi": 9, "metric": [7, 10, 13], "mha": 1, "microsoft": [10, 11], "might": [1, 4, 9, 10, 13, 15], "mightn": 8, "million": [4, 6, 7], "mimic": 6, "min": [7, 8, 12], "min_count": 15, "min_val": 7, "mind": [3, 8, 10], "mini": 15, "minigpt": 3, "minigptconfig": 3, "minilm": 10, "minim": 7, "minor": 4, "minut": [4, 7, 12], "misinform": 5, "mislead": 13, "mismatch": 7, "miss": 5, "mistak": [4, 9], "misus": 5, "mitig": [6, 7], "mix": [11, 14], "mkdir": 12, "mlp": [3, 4, 7], "mmbackward0": 1, "mod": 4, "mode": [4, 7, 10, 12], "model": [4, 8, 9, 15], "model_and_optim": 7, "model_config": 7, "model_dim": 4, "model_nam": 7, "model_nm": 11, "model_s": 7, "model_select": [10, 13], "model_state_dict": 7, "model_typ": 3, "model_with_shortcut": 6, "model_without_shortcut": 6, "modelcheckpoint": 4, "models_dir": 7, "modern": [5, 6, 7, 15], "modifi": [1, 3, 9], "modul": [1, 3, 6, 7, 8, 9, 11, 12, 15], "modulelist": [1, 3, 4, 6], "modulenotfounderror": [3, 4, 6, 8, 9, 11, 12], "modulo": 4, "moment": 3, "monitor": 4, "monolith": 13, "month": 7, "moon": 12, "more": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "moreov": 9, "most": [1, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14], "most_common": 8, "move": [4, 6, 7, 9, 13, 15], "movi": 14, "mpmath": 10, "mr": 7, "mseloss": 6, "msg": 14, "much": [1, 4, 11, 15], "mulbackward0": 1, "multi": [4, 5, 6, 7], "multidict": 10, "multidisciplinari": 13, "multihead": 4, "multiheadattent": [1, 4, 6, 7], "multiheadattentionwrapp": 1, "multinomi": 7, "multipl": [4, 5, 6, 7, 13], "multipli": [1, 6, 8], "multiprocess": 10, "multitask": 6, "must": [1, 4, 6, 7], "mustn": 8, "my": [7, 8], "myqcloud": [7, 11, 13, 15], "myself": 8, "n": [1, 3, 4, 6, 7, 8, 9, 10, 14], "n_cluster": 3, "n_compon": 3, "n_ctx": [3, 7], "n_embd": [3, 7], "n_epoch": 12, "n_head": [3, 6, 7], "n_init": 3, "n_inner": 3, "n_layer": [3, 6, 7], "n_pattern": 9, "n_posit": 3, "n_token": [6, 7], "n_vocab": 7, "na": 10, "nail": 9, "naiv": [1, 14], "naivebayesclassifi": 14, "name": [1, 3, 4, 6, 7, 8, 9, 11, 12, 13], "named_children": 3, "named_ent": 14, "named_paramet": 6, "nan": 13, "narr": 1, "narrat": 4, "narrow": 4, "natur": [2, 4, 5, 8, 9, 11, 14, 15], "nbsp": 13, "nbviewer": 13, "nccl": 10, "ncluster": 3, "ncol": 4, "ne_chunk": 14, "nearli": [8, 11], "necess": 4, "necessari": [1, 4, 6, 7, 8, 13, 14, 15], "necessarili": 4, "need": [1, 3, 4, 7, 8, 10, 11, 14, 15], "needn": 8, "neg": [1, 6, 7, 11, 14], "neg_avg_log_proba": 7, "neglect": 4, "neglig": 6, "neodotlif": 10, "ner": 15, "neri": 14, "network": [1, 2, 4, 5, 15], "networkx": 10, "neural": [1, 4, 5, 6, 15], "neurosci": 10, "neutral": 13, "nevertheless": 4, "new": [1, 3, 4, 5, 7, 11, 14, 15], "new_config": 7, "new_logit": 7, "new_valu": 8, "newcom": 13, "newgeluactiv": 3, "newli": 11, "next": [1, 4, 5, 6, 7, 8, 9, 12, 14, 15], "next_sent": 3, "next_token_id": 7, "next_token_logit": 7, "nfkd": 9, "nhow": 10, "ni": [8, 11], "nice": [4, 15], "ninput": 7, "nlp": [2, 4, 9, 14, 15], "nlplanat": 8, "nltk": [8, 9, 15], "nltk_data": [8, 9, 14, 15], "nmerri": 10, "nn": [1, 3, 4, 6, 7, 12, 14, 15], "nnp": 14, "no_grad": [4, 6, 7, 12], "nois": 4, "noisi": 4, "non": [1, 4, 6, 13, 14], "none": [3, 4, 7, 8, 9, 10, 11, 12, 14, 15], "nonsens": [3, 7], "nor": 8, "norm": 4, "norm1": [4, 6, 7], "norm2": [4, 6, 7], "norm_x": [6, 7], "normal": [1, 4, 9, 10, 13], "normalis": 14, "normalized_shap": 6, "nose": 10, "notabl": [1, 5, 6], "notat": [4, 6, 13], "note": [0, 1, 4, 6, 7, 8, 9, 10, 13, 15], "notebook": [1, 4, 13], "noth": [6, 7, 9], "notic": [7, 8], "notimplementederror": 4, "noun": [3, 13, 14], "noun_list": 3, "noutput": [6, 7], "novel": 4, "now": [1, 3, 4, 6, 7, 8, 9, 10, 11, 13], "nowadai": 7, "np": [3, 4, 7, 10, 11, 12, 13], "nrow": 4, "nsecond": 1, "nto": 8, "nuanc": [5, 13], "nucleu": 5, "null": 3, "num_attention_head": 3, "num_batch": 7, "num_categori": 4, "num_class": [4, 12], "num_epoch": 7, "num_head": [1, 4, 6, 7], "num_hidden_lay": 3, "num_img": 4, "num_label": [4, 11], "num_lay": 4, "num_return_sequ": 3, "num_row": 11, "num_sampl": 7, "num_token": [1, 6, 7], "num_train_epoch": 11, "num_val_exmp": 4, "num_work": 4, "number": [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15], "numel": [6, 7], "numer": [1, 4, 5, 7, 8, 12, 13, 15], "numpi": [3, 4, 7, 10, 11, 12, 13, 14, 15], "nvalid": 7, "nvidia": 10, "nvidia_cublas_cu12": 10, "nvidia_cuda_cupti_cu12": 10, "nvidia_cuda_nvrtc_cu12": 10, "nvidia_cuda_runtime_cu12": 10, "nvidia_cudnn_cu12": 10, "nvidia_cufft_cu12": 10, "nvidia_curand_cu12": 10, "nvidia_cusolver_cu12": 10, "nvidia_cusparse_cu12": 10, "nvidia_nccl_cu12": 10, "nvidia_nvjitlink_cu12": 10, "nvidia_nvtx_cu12": 10, "nvjitlink": 10, "nvrtc": 10, "nvtx": 10, "o": [4, 7, 8, 12, 13, 14, 15], "o_proj": 4, "obia": 8, "object": [1, 3, 4, 5, 11, 13, 14, 15], "observ": [3, 9], "obtain": [1, 3, 4, 6, 7, 8, 14], "occasion": 12, "occur": [7, 8, 13, 15], "occurr": [8, 15], "off": [4, 7, 8, 9], "offer": [4, 6], "offici": 9, "often": [4, 5, 6, 7, 13, 15], "oil": 12, "ok": 7, "okapi": 8, "omega": 1, "omega_": 1, "on_epoch": 4, "on_step": 4, "onc": [4, 7, 8, 9, 11], "one": [1, 4, 6, 7, 8, 9, 10, 11, 13, 15], "one_hot": 4, "ones": [1, 4, 6, 7, 8], "onli": [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "onto": [1, 7], "op": 1, "open": [1, 3, 4, 6, 9, 12, 13, 14, 15], "openai": [5, 6, 7, 13], "openli": 7, "oper": [1, 4, 15], "opportun": 13, "opposit": [13, 15], "opt": [1, 5, 7, 8, 9, 10, 14], "optim": [1, 2, 3, 4, 5, 7, 11, 12, 15], "optimizer_state_dict": 7, "option": [1, 4, 6, 7, 9], "order": [4, 5, 8, 9, 10, 13], "org": [8, 13, 14], "organ": [11, 14], "orig": 7, "orig_dataset": 4, "origin": [1, 4, 6, 7, 8, 11], "ornithorhynchu": 11, "other": [1, 4, 5, 6, 7, 8, 9, 13, 15], "otherwis": [4, 6, 7, 8], "otten": 14, "our": [1, 4, 6, 7, 8, 9, 10, 13], "ourselv": [3, 4, 8], "out": [0, 1, 3, 6, 7, 8, 9, 11, 12, 13], "out_featur": 3, "out_head": [6, 7], "out_id": 3, "out_ln": 6, "out_norm": 6, "out_proj": [1, 6, 7], "outcom": 5, "outlin": [6, 7], "outlook": [12, 13], "output": [1, 3, 4, 5, 6, 7, 9, 11, 12, 13, 15], "output_net": 4, "over": [1, 4, 5, 7, 8, 12], "overal": [1, 3, 4, 5, 13, 15], "overcom": 4, "overfit": [1, 6, 7], "overflow": 1, "overhead": 4, "overlap": [6, 7], "overview": [8, 13], "overwrit": 4, "own": 8, "p": [3, 4, 6, 7, 9, 10, 15], "pa": 10, "packag": [1, 3, 4, 7, 8, 10, 14, 15], "packagenotfounderror": [1, 7], "pad": [3, 4, 12], "pad_id": 3, "pad_sequ": [3, 12], "pad_token_id": 3, "pad_valu": 4, "padded_batch": 3, "padding_valu": 3, "page": [0, 1, 13], "pai": 4, "paint": 7, "pair": [11, 15], "pairwis": 1, "palett": 4, "palm": [4, 5], "panda": [8, 10, 11, 13, 14, 15], "paper": [4, 6], "paragraph": 12, "parallel": [1, 4, 11], "paralleliz": 4, "param": [1, 6, 7, 12], "paramet": [1, 3, 4, 5, 6, 7, 9, 11, 12, 15], "paraphras": 13, "pars": 4, "part": [2, 4, 6, 8, 9, 10, 12, 13], "partial": 4, "particular": [8, 11, 13], "particularli": [4, 13], "pass": [3, 4, 6, 11, 12, 13], "passag": [5, 7], "passion": 10, "patent": 11, "path": [4, 6, 7, 12, 14], "pattern": [4, 5, 9], "pcfg": 3, "pd": [8, 10, 11, 13], "pdf": 7, "pe": 4, "pe_": 4, "peaki": 7, "penalti": 5, "peopl": [4, 11], "per": [4, 6, 11], "per_device_eval_batch_s": 11, "per_device_train_batch_s": 11, "perceptron": 14, "perceptrontagg": 14, "perfect": 4, "perform": [1, 3, 4, 5, 6, 8, 9, 13, 14, 15], "perhap": 11, "perm_inp_data": 4, "perm_pr": 4, "permut": 4, "perplex": 3, "persist": 4, "person": [3, 13, 14], "perspect": 5, "pertain": 13, "petter": 12, "phase": 5, "phenomena": 3, "phil": 13, "phillip": 4, "philosophi": 8, "phinea": 10, "phlipp": 4, "photo": [10, 13], "phrase": [3, 5, 11, 13], "phrase_matching_test": 11, "phrase_matching_train": 11, "pi": [4, 6, 7], "pick": [7, 11], "pickl": 14, "pictur": [3, 4, 7], "piec": [11, 13], "piecewis": 6, "pillow": 10, "pin_memori": 4, "pip": [4, 7, 8, 9, 10, 13, 14, 15], "pipe": 9, "pipelin": [3, 9], "pivot": [5, 13], "pixel": 4, "pizza": 7, "pkg": 7, "pl": 4, "place": [1, 7, 8, 12, 13, 15], "placehold": [1, 6], "plai": [4, 5, 8, 9, 12], "plain": 4, "plan": 7, "plant": 13, "platform": 4, "platypu": 11, "pleas": [3, 4, 7, 10, 13, 14], "plot": [3, 4, 6, 7, 8], "plot_attention_map": 4, "plot_loss": 7, "plot_titl": 8, "plotli": 8, "plotly_dark": 8, "plt": [3, 4, 6, 7], "plu": 12, "plug": 6, "po": [4, 13, 14], "point": [6, 11], "polar": 13, "polit": 8, "pollut": 11, "pond": 13, "pool": 12, "pooler": [3, 11], "popular": [1, 4, 9, 15], "popularli": 9, "porterstemm": [9, 14], "portion": 13, "pos_emb": [6, 7], "pos_tag": 14, "posit": [1, 3, 6, 7, 11], "position_embed": 3, "position_embedding_typ": 3, "positional_encod": 4, "positionalencod": 4, "possibl": [4, 7], "possibli": 11, "post": [4, 9, 12], "post0": 10, "potenti": [4, 5], "pow": [6, 7], "power": [4, 5, 8, 9], "practic": [1, 2, 4, 5, 6, 7, 11, 13, 15], "pranav": 9, "pre": [2, 4, 5, 8, 11, 13, 14], "preced": [1, 5], "precis": [10, 11], "pred": [4, 11], "predict": [1, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15], "prefer": [1, 5, 15], "prefix": [3, 14], "preliminari": 13, "premis": 13, "prepar": [3, 4, 6, 7, 11], "preposit": [8, 13], "preprocess": [4, 8, 9, 12], "presenc": 13, "present": 9, "preserv": [3, 13, 15], "pretrain": [3, 4, 6], "pretrained_fil": 4, "pretrained_filenam": 4, "pretrained_model": 4, "pretti": [3, 9, 13], "prevent": [4, 6, 8], "previou": [1, 4, 6, 7, 8, 12], "previous": [1, 6, 7], "price": 12, "primari": [1, 13, 15], "primarili": [5, 7], "principl": 5, "print": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "print_gradi": 6, "print_sampled_token": 7, "prior": 1, "privat": 12, "prob": 7, "proba": [6, 7], "probabilist": 5, "probabl": [1, 4, 5, 6, 7, 8, 11, 15], "problem": [4, 6, 9, 11], "process": [1, 2, 4, 6, 7, 8, 11, 14, 15], "process_datasets_by_token": 12, "produc": [1, 5, 6, 7, 10, 13, 14, 15], "product": [1, 4, 6, 7, 11], "program": 13, "progress": 7, "project": [1, 6, 7, 8, 14, 15], "promin": 3, "prompt": [3, 5], "prompt_ind": 3, "pronoun": 13, "proper": 13, "properli": 8, "properti": [1, 4, 13], "proport": 8, "propos": 6, "provid": [3, 4, 5, 6, 7, 8, 13, 14], "pso": 15, "psychologi": 10, "pth": 7, "public": 7, "publish": 4, "punct": 12, "punctuat": [8, 12, 13], "punkt": [8, 9, 15], "pure": [1, 4], "purp": 10, "purpos": [1, 4, 7, 10, 14], "push": 13, "put": [1, 12], "px": 8, "py": [1, 3, 4, 7, 10, 14], "py2": 10, "py3": [8, 9, 10], "py39": 10, "pyarrow": 10, "pyarrow_hotfix": 10, "pyfum": 15, "pyplot": [3, 4, 6, 7], "python": [1, 7, 8, 9, 10, 14, 15], "python3": [1, 7, 8, 9, 10, 14], "pytorch": [1, 6], "pytorch_lightn": 4, "pytz": [10, 15], "pyyaml": 10, "q": [1, 4, 6, 8], "q_b": 7, "q_w": 7, "qkv": 4, "qkv_bia": [1, 6, 7], "qkv_proj": 4, "qualiti": 7, "quantit": 8, "queri": [1, 3, 4, 6, 7, 8], "query_2": 1, "question": [3, 5, 9, 11, 13], "quick": [1, 6, 7, 9, 13], "quickli": [8, 10, 11], "quiet": [4, 13, 14, 15], "quietli": 12, "quit": [4, 7, 9], "r": [7, 8, 9], "radam": 4, "radford": 6, "raikot": 9, "raimi": 4, "rais": [1, 4, 5, 7, 14], "ran": [3, 14], "rand": [1, 6], "randint": 4, "randn": 6, "random": [1, 3, 4, 6, 15], "random_split": 12, "random_st": [3, 10], "randomli": [1, 4, 15], "rang": [1, 3, 4, 5, 6, 7, 8, 12, 13, 15], "rank": 8, "rare": [4, 8, 15], "raschka": [1, 6, 7], "rate": [1, 6, 7, 11, 12], "rather": [4, 7, 8, 13], "ratio": [7, 8, 11], "ratul": 8, "raw": [4, 8], "raw_text": 15, "rcparam": 4, "rdgy": 4, "re": [1, 8, 9, 11, 12, 13], "reaction": 13, "read": [1, 7, 13], "read_csv": [8, 10, 11, 13], "readabl": 6, "reader": 7, "readi": [1, 8, 14], "real": [1, 5, 10, 13], "realist": 13, "realli": [7, 13], "realm": 13, "reason": [4, 6, 7, 11], "recal": 10, "recalcul": 4, "recap": 7, "receiv": 5, "recent": [1, 3, 4, 6, 7, 8, 9, 11, 12, 14], "recogn": [4, 5, 13], "recognit": 13, "recommend": [1, 3, 4, 7, 14], "record": 13, "rect": 7, "rectifi": 6, "recurr": 8, "recurs": 3, "recursive_print": 3, "red": 8, "redesign": 8, "reduc": [1, 6, 7, 9, 14], "refactor": 9, "refer": [1, 4, 6, 12, 13], "referenc": 6, "refin": 5, "reflect": [4, 8, 15], "refr": 7, "regard": 4, "regardless": 5, "regex": [9, 10], "region": 11, "regist": 13, "register_buff": [1, 4, 6, 7], "register_pytree_nod": 10, "regress": [5, 10, 13], "regular": [4, 5, 7, 9, 11], "reimplement": 6, "reinforc": 5, "rel": [4, 7, 8, 12], "relat": [4, 5, 7, 8], "relationship": [5, 13, 15], "relev": [1, 4, 5, 7, 8, 13], "reliabl": 3, "relu": [4, 6], "relubackward0": 6, "remain": 13, "rememb": 4, "remov": [1, 3, 4, 6, 7, 8], "remove_accented_char": 9, "remove_p": 9, "remove_special_charact": 9, "remove_stopword": 9, "renam": 11, "rename_column": 11, "render": 13, "renorm": 1, "rentinget": 7, "reorder_and_upcast_attn": 3, "repeat": [1, 6], "repetit": 4, "replac": [4, 7, 9, 11, 12], "repo_typ": [8, 10], "report": [6, 11], "report_to": 11, "repositori": [6, 7], "repres": [1, 4, 6, 7, 8, 9, 11, 15], "represent": [1, 3, 4, 5, 6, 7, 9, 12, 13, 15], "reproduc": [4, 7], "reput": 12, "request": [4, 7, 10, 13], "requir": [1, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15], "requires_grad": [1, 4], "rerun": 13, "rescal": [4, 7], "research": [1, 6, 8, 9], "reservoir": 12, "reset": 7, "reset_orig": 4, "reshap": [4, 7, 12], "resid_dropout": 3, "resid_pdrop": 3, "residu": [4, 6], "resiz": 4, "resnet": 4, "resnet34": 4, "resolut": [4, 13], "resourc": [5, 7, 14, 15], "resource_nam": 14, "resource_not_found": 14, "respect": [1, 4, 6, 8, 12], "respond": 13, "respons": [5, 7, 13], "rest": 13, "restart": [8, 10], "restrict": 7, "result": [1, 3, 4, 5, 7, 8, 9, 12, 13], "resum": 9, "retain": 9, "retrain": 4, "retriev": 8, "return": [1, 3, 4, 6, 7, 8, 9, 11, 12, 14, 15], "return_attent": 4, "reus": [1, 6], "reusabl": 9, "reuter": 12, "revers": 4, "reverse_model": 4, "reverse_result": 4, "reversedataset": 4, "reversepredictor": 4, "reversetask": 4, "review": 4, "revisit": 6, "revolution": 9, "revolutionari": 9, "reward": 5, "rewritten": 1, "rexmechicular": 7, "rhynch": 11, "ridg": 13, "ridgeclassifi": 13, "ridgeclassifierifittedridgeclassifi": 13, "riemer": 10, "right": [4, 6, 7], "rigor": 9, "rishav": 10, "riv": 7, "rnn": [1, 3, 4], "roam": [8, 15], "rob": 8, "roberta": 5, "robot": 8, "robust": [4, 5, 9], "rocket": 9, "rod": 10, "role": [3, 4, 5, 9, 14], "rong": 13, "room": 7, "root": [1, 4, 6, 9, 12, 14], "root_dir": 4, "rose": 12, "rotat": 7, "round": 3, "row": [1, 4, 6, 7, 11], "row_2_sum": 1, "row_sum": 1, "rsplit": 4, "rtype": 14, "rule": [3, 5, 9, 13], "run": [1, 3, 4, 6, 7, 10, 11, 12, 14], "run_line_mag": 8, "runner": [9, 14], "runtim": 10, "rush": 9, "ryan": 10, "r\u00e9sum\u00e9": 9, "sa_v1": 1, "sa_v2": 1, "safetensor": 10, "sai": [11, 13], "said": 9, "salt": [4, 13], "samaranayak": 10, "same": [1, 3, 4, 6, 7, 8, 9, 11, 12, 13], "sampl": [0, 4, 5, 6, 8, 10, 12, 15], "sample1": 12, "sample2": 12, "sample_img_set": 4, "sample_input": 6, "sample_submiss": 13, "sampled_id": 7, "samplen": 12, "saniti": [1, 7], "sarcasm": 13, "sask": 13, "sat": [3, 13], "satisfi": [8, 9, 10, 15], "save": [4, 9, 13, 15], "save_fil": 4, "save_hyperparamet": 4, "save_weights_onli": 4, "saved_model": 4, "savefig": 7, "saw": [3, 12], "scalar": 4, "scale": [1, 4, 5, 6], "scale_attn_by_inverse_layer_idx": 3, "scale_attn_weight": 3, "scaled_dot_product": 4, "scaled_logit": 7, "scaled_proba": 7, "scatter": 3, "scenario": 9, "schedul": [4, 11, 12], "scheme": 1, "sci": 10, "sci_mod": 6, "scienc": 10, "scientif": 6, "scikit": [10, 13, 14, 15], "scikit_learn": 10, "scipi": [10, 15], "scope": [10, 11], "score": [1, 3, 4, 6, 7, 8, 10, 11, 13], "scratch": [1, 3, 7], "scroll": 15, "sea": 9, "seaborn": 4, "seamless": 13, "search": [5, 8, 14], "sebastiaan": 8, "sebastian": [1, 6, 7], "sec": 12, "second": [1, 3, 4, 7, 8, 12, 13], "second_head": 1, "second_r": 1, "secondli": 4, "section": [1, 2, 6, 7, 11, 13], "see": [0, 1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "seed": [4, 7, 11], "seed_everyth": 4, "seem": 4, "seen": [4, 7], "segment": 1, "select": [1, 7], "self": [3, 5, 6, 7, 12, 14, 15], "self_attn": 4, "selfattention_v1": 1, "selfattention_v2": 1, "sell": [9, 15], "seller": 12, "semant": [5, 9, 15], "senet": 3, "sens": [4, 7, 13], "sent": 11, "sent_str": 3, "sentenc": [1, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15], "sentence_str": 3, "sentence_transform": 10, "sentencetransform": 10, "sentiment": [5, 11, 13, 14], "sep": 14, "separ": [1, 4, 11], "seq": 3, "seq_len": [4, 6, 7, 12], "seq_length": 4, "seq_relationship": 3, "seqlen": 4, "sequenc": [5, 6, 7, 9, 11, 12, 15], "sequenti": [4, 6, 7], "seri": 4, "serv": [2, 7], "server": 7, "set": [1, 3, 6, 9, 10, 12, 13, 14, 15], "set_cmap": 4, "set_label": 4, "set_printopt": 6, "set_siz": 4, "set_them": 4, "set_titl": 4, "set_xlabel": [4, 7], "set_xtick": [4, 7], "set_xticklabel": [4, 7], "set_ylabel": [4, 7], "set_ylim": 4, "set_ytick": 4, "set_yticklabel": 4, "setanomalydataset": 4, "setanomalytask": 4, "setup": [1, 4], "sever": [1, 5, 6, 8, 13], "sex": 8, "sg": 15, "sgd": [7, 12, 15], "shakespear": 8, "shall": 9, "shan": 8, "shanghai": [7, 11, 13, 15], "shape": [1, 3, 4, 5, 6, 7, 10, 13], "share": [4, 7, 13, 14], "sharp": 4, "sharper": 7, "she": [7, 8, 9], "sheep": 3, "shell": 9, "shift": [6, 7, 15], "shoot": 13, "shore": 9, "short": [1, 3, 6, 7, 11, 12], "shortag": 12, "shortcut": 7, "shorten": [7, 13], "shorter": 6, "shorthand": 1, "should": [1, 4, 6, 8, 11, 15], "shouldn": 8, "show": [3, 4, 6, 7, 8, 13], "showlegend": 8, "shown": [1, 4, 7, 9, 11, 15], "shuffl": [4, 6, 7, 12], "side": [1, 12], "sight": 9, "sigmoid": 6, "signific": [1, 4, 5, 8, 13, 14], "significantli": 5, "similar": [1, 4, 6, 7, 8, 9, 11, 13, 14, 15], "similarli": 8, "simon": 10, "simp": 15, "simpl": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "simpler": [1, 4, 6], "simplest": [1, 8], "simpli": [1, 3, 4, 7, 9], "simplic": [1, 4, 6, 7], "simplif": 13, "simplifi": [1, 3, 4], "simul": [1, 3], "sin": 4, "sinc": [1, 3, 4, 7, 9], "sine": 4, "singl": [4, 9, 15], "singular": [8, 13], "sinha": 10, "sister": 13, "site": [3, 8, 9, 10, 14, 15], "situat": 13, "six": [10, 15], "size": [1, 3, 4, 5, 6, 7, 11, 12, 15], "sketch": 7, "skill": [4, 13], "skip": [4, 6], "skipgram_model": 15, "sklearn": [3, 10, 13], "slept": 3, "slicebackward0": 6, "slide": [6, 7], "slight": [1, 4], "slightli": [4, 8, 9], "slot": 13, "slow": 4, "slower": [9, 11], "slowli": 4, "small": [0, 1, 3, 4, 6, 7, 9, 11, 15], "smaller": [6, 7], "smallest": [4, 6, 9], "smart": [3, 15], "smell": [3, 10], "smith": 14, "smooth": [4, 6], "sn": 4, "snowballstemm": 9, "so": [1, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15], "soar": 12, "societ": 5, "societi": 8, "softmax": [1, 4, 6, 7, 12], "softmax_na": 1, "softmax_with_temperatur": 7, "softmaxbackward0": [1, 6], "sole": 9, "solv": [4, 9, 11, 12], "some": [3, 4, 6, 7, 8, 11, 13], "someon": 13, "someth": [4, 7, 11], "sometim": 7, "somewhat": [8, 11], "sort": 4, "sorted_indic": 4, "soudelor": 13, "sound": 4, "sourc": [1, 3, 4, 6, 7, 13, 14, 15], "space": [1, 4, 9, 10, 12, 13, 15], "spam": [13, 14], "spars": [12, 13], "speaker": 13, "special": 5, "specif": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15], "specifi": [4, 7, 12], "speech": 9, "speed": 5, "spell": [9, 13], "spend": 7, "spichak": 10, "spl": 9, "split": [3, 4, 6, 7, 11, 12, 14, 15], "split_idx": 7, "spokan": 13, "spot": 13, "spread": 5, "spreadsheet": 13, "sqrt": [1, 4, 6, 7], "squar": [1, 3, 6], "squeez": [4, 6, 7, 12], "src": 15, "st": 12, "stabil": [1, 4, 6], "stabl": 1, "stack": [4, 6], "stage": 5, "stanc": 13, "stand": [1, 7, 13], "standard": [1, 3, 4, 6, 7, 13], "start": [1, 4, 6, 7, 9, 10, 13, 14, 15], "start_context": [6, 7], "start_tim": 12, "startswith": 4, "state": [1, 2, 4, 8, 9, 13], "state_dict": 7, "statement": [9, 12, 13], "static": [7, 11, 13, 15], "statist": [4, 5, 8, 15], "stderr": 4, "stem": 2, "stemmed_token": [9, 14], "stemmer": [9, 14], "step": [3, 4, 6, 7, 8, 9, 11, 12, 15], "steplr": 12, "ster": 12, "still": [4, 7, 10], "stock": 12, "stood": 3, "stop": [3, 4], "stopword": 14, "store": [4, 7, 10, 11, 15], "stori": [7, 8], "str": [4, 9, 12, 14], "strategi": [4, 5, 11], "stratifi": 10, "stream": 11, "streamlin": 1, "street": 12, "stren": 7, "strength": 5, "strictli": 1, "stride": [6, 7], "string": [1, 7, 9, 12], "strip": 9, "strive": 13, "strongli": 3, "stroud": 7, "structur": [0, 1, 2, 4, 5, 12, 13], "struggl": 3, "studi": 2, "style": [5, 15], "sub": [8, 9, 11], "sub_train_": 12, "sub_valid_": 12, "subclass": [1, 4, 7], "subdomain": 9, "subject": 13, "submodul": 6, "subplot": [4, 6, 7], "subplots_adjust": 4, "subprocess": 4, "subscript": 1, "subsect": 7, "subsequ": [1, 12], "subspac": 1, "substanti": 5, "substitut": 3, "subtract": 6, "subword": 14, "success": 4, "successfulli": [1, 8, 9], "suffer": 1, "suffici": 4, "suffix": 14, "suggest": [8, 11], "suit": 6, "suitabl": [7, 13], "sum": [1, 3, 4, 6, 12, 15], "sum_i": 6, "summar": [1, 4, 5, 7, 9, 13], "summari": [1, 12], "summary_activ": 3, "summary_first_dropout": 3, "summary_proj_to_label": 3, "summary_typ": 3, "summary_use_proj": 3, "summat": 1, "summer": 12, "super": [1, 3, 4, 6, 7, 12, 15], "supervis": 5, "support": [1, 4, 6, 7, 10, 13], "suppos": [1, 6, 7, 8], "suppress": 3, "sure": [1, 3, 4, 9], "surfac": [4, 9], "surpris": 7, "surround": 15, "surviv": 10, "swam": 3, "swap": 4, "swiglu": 6, "sy": [13, 14, 15], "symbol": [1, 9], "symlink": 10, "sympi": 10, "synergi": 10, "syntact": 15, "system": [1, 3, 5, 10, 13], "sz": 12, "t": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13], "t5": 5, "tabl": 8, "tacc": 12, "tackl": 5, "tag": [8, 10, 13], "tagged_token": 14, "tagger": 14, "tags_list": 10, "tagset": 14, "taiwan": 13, "take": [4, 7, 8, 9, 13, 15], "taken": 4, "talk": 6, "tall": 3, "tandem": 5, "tanh": [6, 7], "tapoel": 12, "tapul": 12, "tar": 4, "target": [1, 4, 5, 6, 7, 11, 13, 15], "target_batch": 7, "target_chunk": [6, 7], "target_id": [6, 7], "target_probas_1": 7, "target_probas_2": 7, "targets_flat": 7, "task": [1, 3, 4, 5, 6, 7, 9, 14, 15], "task_specific_param": 3, "tbd": [1, 3, 6, 7, 8], "team": 15, "technic": [1, 3, 6], "techniqu": [1, 2, 4, 5, 9, 13, 14, 15], "technologi": 13, "tell": [4, 13], "temperatur": 3, "templat": [4, 8], "ten": [7, 8], "tenac": 8, "tend": 4, "tensor": [1, 3, 4, 6, 7, 12, 15], "tensorboard": 4, "tensorflow": [7, 9], "term": [4, 9, 13, 15], "terribl": 13, "test": [4, 8, 12, 13, 14], "test_acc": 4, "test_anom_dataset": 4, "test_anom_load": 4, "test_datase_seq": 12, "test_dataset": 12, "test_dataset_label": 12, "test_dataset_text": 12, "test_df": 13, "test_feat": 4, "test_feat_fil": 4, "test_label": 4, "test_load": 4, "test_result": 4, "test_set": 4, "test_set_featur": 4, "test_siz": 10, "test_step": 4, "test_text": 14, "test_vector": 13, "text": [1, 3, 4, 5, 8, 11, 12, 15], "text1": 11, "text2": 11, "text_data": 7, "text_to_token_id": 7, "text_to_word_sequ": 9, "text_token": 9, "texts_to_sequ": 12, "textsenti": 12, "textual": [5, 9], "tf": 9, "tf_idf": 8, "than": [1, 4, 7, 8, 9, 12, 13, 15], "thank": [1, 3, 4, 6, 7, 8, 9, 11, 13, 14, 15], "thei": [1, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15], "theirs": 8, "them": [1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "themselv": 8, "theori": 13, "therebi": 4, "therefor": [4, 6, 9, 11], "thereof": [1, 7], "thi": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "thin": 3, "thing": [1, 8, 9, 11], "think": [1, 6, 13], "third": 12, "tho": 11, "those": [1, 4, 7, 8, 11, 13], "though": [7, 9], "thought": [7, 9], "thousand": [7, 11], "thread": 4, "threadpoolctl": 10, "three": 1, "threw": 7, "through": [1, 4, 5, 6, 8, 10, 11, 13, 15], "throughout": [4, 7], "thu": [4, 5, 6, 8], "tick": 7, "tick_param": 4, "tight_layout": [6, 7], "tiktoken": [6, 7], "till": 15, "time": [1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14], "timeout": 10, "timestamp": [8, 10], "titl": [4, 6, 8, 10], "tloss": 12, "to_low": 9, "to_rgb": 4, "todai": 11, "todens": 13, "togeth": [1, 4, 12, 15], "toi": 14, "tok_d": 11, "tok_emb": [6, 7], "tok_func": 11, "token": [0, 4, 5, 6, 7, 8, 10, 12, 13, 15], "token_count": 8, "token_embed": 3, "token_embedding_2d": 3, "token_id": [6, 7], "token_ids_to_text": 7, "token_str": 3, "token_type_id": 11, "tokenize_sent": 3, "tokenized_corpu": 15, "tokens_seen": 7, "tokz": 11, "tolist": [3, 4, 6, 7], "too": [4, 7, 8, 9, 11], "took": [3, 4], "toolkit": [9, 14], "top": [1, 8, 9, 11, 14], "top_k": [3, 7], "top_logit": 7, "top_n": 8, "top_p": 3, "top_po": 7, "topic": [7, 11, 15], "topk": 7, "topk_proba": 7, "torch": [1, 3, 4, 6, 7, 10, 12, 15], "torch_data_mean": 4, "torch_data_std": 4, "torch_hom": 4, "torchtext": 12, "torchvis": 4, "total": [1, 6, 7, 8, 11, 12, 15], "total_acc": 12, "total_char": 7, "total_exampl": 15, "total_loss": [7, 12, 15], "total_param": 6, "total_params_gpt2": 6, "total_size_byt": 6, "total_size_mb": 6, "total_token": 7, "totensor": 4, "toward": [4, 5, 6, 7, 12, 13], "tpu": 4, "tqdm": [4, 7, 9, 10], "tra": 10, "traceback": [1, 3, 4, 6, 7, 8, 9, 11, 12, 14], "track": 7, "track_tokens_seen": 7, "tracker": 1, "trade": 8, "tradit": 6, "train": [1, 2, 4, 5, 6, 9, 13, 14, 15], "train_acc": [4, 12], "train_anom_dataset": 4, "train_anom_load": 4, "train_anomali": 4, "train_data": 7, "train_dataset": [11, 12], "train_dataset_label": 12, "train_dataset_seq": 12, "train_dataset_text": 12, "train_df": 13, "train_feat": 4, "train_feat_fil": 4, "train_indic": 4, "train_label": 4, "train_len": 12, "train_load": [4, 7], "train_loss": [7, 12], "train_model_simpl": 7, "train_ratio": 7, "train_result": 4, "train_revers": 4, "train_set": 4, "train_set_feat": 4, "train_set_featur": 4, "train_test_split": [10, 11], "train_token": 7, "train_vector": 13, "trainabl": 6, "trainer": [4, 11], "training_data": 14, "training_ratio": 7, "training_step": 4, "trainingargu": 11, "tran": 12, "trans_verbs_list": 3, "transcrib": 13, "transfer": [5, 7], "transform": [1, 2, 5, 9, 10, 11, 12, 13], "transformerblock": [6, 7], "transformerencod": 4, "transformerpredictor": 4, "transformers_vers": 3, "transit": 3, "translat": [1, 4, 5, 9, 11, 12, 13], "transpos": [1, 4, 6, 7, 12], "treat": [9, 11], "tree": [4, 5], "trf_block": [6, 7], "tri": 9, "triag": 11, "trial": [5, 11], "trick": 12, "tril": 1, "trillion": [5, 7], "triton": 10, "triu": [1, 6, 7], "troubl": 9, "troubleshoot": 3, "true": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "truncat": [1, 6, 7], "trust": 13, "try": [3, 4, 6, 7, 8, 9, 10, 13], "tsne": 3, "tuban": 8, "tune": [5, 9], "tupl": [12, 14], "turn": 11, "turner": 12, "turni": 8, "tutori": [4, 9, 13], "tutorial6": 4, "tv": 3, "tweak": 8, "tweet": 13, "twice": 4, "twini": 7, "two": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15], "txt": [6, 7], "txt1": 6, "txt2": 6, "ty": 6, "type": [3, 5, 6, 9, 10, 12, 13, 15], "type_vocab_s": 3, "typhoon": 13, "typic": [5, 8, 13, 14], "tzdata": 10, "u": [3, 4, 7, 8, 9, 10, 11, 13, 15], "ultra": 12, "un": 10, "unabl": [1, 13], "unacc": 9, "unbias": [6, 7], "uncas": 3, "uncertain": 7, "uncom": 7, "uncommon": 11, "under": [8, 9, 15], "underflow": 1, "undergo": 5, "underli": [13, 15], "understand": [4, 5, 13, 15], "understood": [4, 7], "undetermin": 13, "uneven": 4, "unexpect": 3, "unicodedata": 9, "uniform": 12, "uniform_": 12, "uniformli": 7, "unintend": 1, "uniqu": [9, 11, 13], "unit": [1, 6], "unlabel": 5, "unlik": [6, 7], "unlog": 12, "unmask": 3, "unnecessari": 9, "unnorm": 1, "unord": 4, "unrol": [1, 6, 7], "unsafeviewbackward0": [1, 6], "unsplash": 10, "unsqueez": [4, 6, 7, 15], "unsupervis": 6, "until": 8, "unusu": 4, "unzip": [8, 9], "up": [1, 7, 8, 9, 11, 12, 15], "upcom": [1, 6], "updat": [1, 7, 8, 10, 12], "update_layout": 8, "upgrad": 10, "upper": [7, 15], "url": [4, 7, 8, 10], "urllib": [4, 7], "urllib3": 10, "urlopen": 7, "urlretriev": 4, "us": [1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "usag": [3, 7, 8, 15], "use_cach": 3, "use_shortcut": 6, "useabl": 6, "user": [7, 8, 10, 13, 15], "userwarn": 10, "usr": 14, "usual": [1, 3, 4, 6, 9, 13], "uszkoreit": 4, "utf": [7, 9], "util": [1, 3, 4, 5, 6, 7, 10, 12, 13], "utter": 8, "uva": 4, "ux": 8, "v": [1, 4, 6, 7, 8], "v2": 10, "v3": 11, "v_b": 7, "v_w": 7, "val": [4, 7], "val_acc": 4, "val_anom_dataset": 4, "val_anom_load": 4, "val_data": 7, "val_feat": 4, "val_indic": 4, "val_label": 4, "val_load": [4, 7], "val_loss": 7, "val_result": 4, "val_token": 7, "valid": [4, 13], "valid_acc": 12, "valid_loss": 12, "validation_step": 4, "valu": [1, 3, 4, 6, 7, 8, 10, 12, 13, 15], "valuabl": 13, "value_2": 1, "valueerror": 7, "van": 14, "vanilla": 4, "vanish": 6, "var": [6, 7], "varbackward0": 6, "vari": [4, 8], "variabl": [6, 10], "varianc": [4, 6], "variant": [1, 4], "variat": 13, "varieti": [7, 9], "variou": [4, 5, 6, 12, 13], "vast": [5, 6, 7], "vaswani": 4, "vbz": 14, "ve": [8, 10, 11], "vector": [1, 4, 6, 7, 8, 9, 15], "vector_represent": 15, "vector_s": 15, "vector_sizewindow": 15, "verb": [3, 13, 14], "verbal_sent": 3, "verbatim": 7, "verbos": 4, "verdict": 7, "veri": [1, 4, 6, 7, 8, 9, 11], "verif": 1, "verifi": [4, 8], "versatil": 5, "version": [1, 4, 6, 7, 10, 12, 13], "via": [1, 4, 7], "video": 4, "view": [1, 3, 4, 6, 7], "viewbackward0": 1, "vindic": 7, "vinyal": 4, "violat": 7, "violent": 13, "vision": [4, 6], "visual": [4, 7, 8, 15], "visualize_exmp": 4, "visualize_predict": 4, "vmin": 4, "vocab": [6, 7, 11, 15], "vocab_s": [3, 6, 7, 12, 15], "vocabulari": [6, 7, 8, 12], "vol": 10, "volcano": 4, "vp": 3, "w": [7, 8], "w_2": 4, "w_k": 1, "w_kei": [1, 6, 7], "w_q": 1, "w_queri": [1, 6, 7], "w_v": 1, "w_valu": [1, 6, 7], "wa": [1, 4, 6, 7, 8, 9, 12, 14], "wai": [1, 4, 6, 7, 8, 9, 11, 13], "walk": [1, 3], "wall": 12, "wang": 3, "want": [1, 3, 4, 7, 13], "warm": 11, "warmup": [4, 11], "warmup_ratio": 11, "warn": [3, 4, 10, 11], "wasn": [7, 8], "wasn\u0645": 7, "wast": 9, "watch": 7, "wave": 4, "wavelength": 4, "we": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "weather": 15, "websit": 4, "week": [7, 12], "weigh": 5, "weight": [3, 4, 6, 8, 9, 11, 12, 13, 15], "weight_decai": [7, 11], "welcom": 9, "well": [1, 4, 6, 7, 10, 12, 13, 15], "weng": 4, "went": 4, "were": [1, 3, 6, 7, 8, 9, 11, 12], "weren": 8, "what": [1, 3, 4, 7, 8, 11], "when": [1, 3, 4, 6, 7, 8, 13, 15], "where": [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15], "wherea": [1, 4, 7], "whether": [4, 5, 8, 9, 10, 11, 13, 15], "which": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "while": [1, 3, 4, 8, 9, 13], "white": 9, "whl": [8, 9, 10], "who": 8, "whole": [4, 8], "whom": 8, "why": [3, 4, 6, 8], "wide": [3, 5, 8, 9, 11], "wider": 4, "widespread": [5, 13], "width": 15, "wiki": 15, "wikidata": 13, "wikipedia": 8, "wildfir": 13, "window": [6, 7, 10, 13, 15], "wise": 1, "within": [1, 5, 6, 8, 15], "without": [4, 5, 6, 7, 9, 10, 13, 14], "won": [8, 9], "word": [4, 5, 6, 7, 8, 9, 11, 12, 13], "word2vec": 9, "word_index": 15, "word_map": 3, "word_pair": 15, "word_seq": 3, "word_to_index": 15, "word_to_lookup": 15, "word_token": [8, 9, 14, 15], "wordnet": [9, 13, 15], "wordnetlemmat": [9, 14], "work": [1, 4, 6, 7, 8, 10, 13, 14], "worker": [4, 15], "world": [3, 8, 13], "worm": 4, "worri": 12, "wors": 4, "would": [1, 4, 6, 7, 8], "wouldn": [6, 8], "wpe": [3, 7], "wrap": 1, "write": [1, 4, 7], "written": 13, "wrong": 4, "wrote": 11, "wte": [3, 7], "wv": 15, "www": 14, "x": [1, 3, 4, 5, 6, 7, 8, 10, 11], "x64": [1, 7, 8, 9, 10, 14], "x_2": 1, "x_i": [1, 6], "x_j": 1, "x_test": 10, "x_train": 10, "xavier_uniform_": 4, "xl": [6, 7], "xlabel": [3, 4, 6], "xw_1": 4, "xxhash": 10, "y": [6, 7, 8, 10], "y_gelu": 6, "y_relu": 6, "y_test": 10, "y_train": 10, "yarl": 10, "ye": [4, 7], "year": [4, 9, 11], "yet": [4, 7], "ylabel": [3, 4, 6], "york": 14, "you": [0, 1, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "your": [9, 10, 11], "yourself": [4, 8, 10], "yourselv": 8, "youtub": 4, "ys_zipf": 8, "z": [1, 9], "z0": 9, "za": 9, "zebra": 3, "zero": [1, 4, 6, 7, 13], "zero_": 12, "zero_grad": [3, 7, 12, 15], "zhongmeiqi": [8, 10, 15], "zip": [6, 8, 9, 12], "\u00e2": 9, "\u00e9": 9, "\u0142ukasz": 4, "\u03c6": 6, "\u03c9": 1}, "titles": ["Welcome to ZMQ\u2019s NLP", "<span class=\"section-number\">9.1. </span>Coding Attention Mechanisms", "<span class=\"section-number\">9. </span>Large Language Models Basic", "<span class=\"section-number\">9.3. </span>Transformers for Language Modelling", "<span class=\"section-number\">9.2. </span>Transformer", "<span class=\"section-number\">8. </span>Introduction", "<span class=\"section-number\">10. </span>Implementing a GPT model from Scratch To Generate Text", "<span class=\"section-number\">10.10. </span>Pretraining on Unlabeled Data", "<span class=\"section-number\">3. </span>TF-IDF\uff08Term frequency-inverse document frequency \uff09", "<span class=\"section-number\">2.6. </span>Project: Beginner\u2019s Guide to Text Pre-Processing", "<span class=\"section-number\">7. </span>Project: Classify Medium Articles with Embeddings", "<span class=\"section-number\">2.7. </span>Project: Getting Start NLP with classification task", "<span class=\"section-number\">6. </span>Project: News topic classification tasks", "<span class=\"section-number\">1. </span>Natural Language Processing", "<span class=\"section-number\">2. </span>Text Preprocessing", "<span class=\"section-number\">5. </span>Word embedding"], "titleterms": {"": [0, 8, 9, 13], "A": [1, 5], "Of": 14, "On": 3, "The": [1, 4], "To": 6, "accent": 9, "acknowledg": [1, 3, 4, 6, 7, 8, 9, 11, 13, 14, 15], "activ": 6, "ad": 6, "addit": 1, "advantag": 15, "ai": 7, "all": [1, 9], "alphanumer": 9, "an": [6, 7], "anomali": 4, "appli": 1, "ar": 5, "architectur": [4, 5, 6], "articl": [8, 10], "attend": 1, "attent": [1, 6], "bag": 15, "base": 13, "basic": 2, "beginn": 9, "bert": 3, "block": 6, "broad": 5, "brown": 8, "build": [3, 12, 13], "calcul": 7, "captur": 1, "causal": 1, "cbow": 15, "challeng": 13, "charact": 9, "chatbot": 13, "class": 1, "classif": [11, 12, 13], "classifi": 10, "cloze": 3, "code": [1, 6, 13, 14], "common": 14, "compact": 1, "compon": 13, "comput": 1, "conclus": [4, 9], "connect": 6, "construct": 5, "continu": 15, "control": 7, "convert": 9, "corpu": 8, "cross": 7, "data": [1, 7, 12, 13], "dataset": [3, 10, 12], "decod": 7, "depend": 1, "detect": [4, 13], "differ": 1, "disadvantag": 15, "discours": 13, "do": [3, 5], "document": [8, 13], "doe": 3, "download": [9, 10, 12], "dropout": 1, "eda": 11, "embed": [10, 15], "encod": 4, "entiti": [13, 14], "entropi": 7, "etc": 3, "evalu": [7, 10], "exampl": [8, 14], "experi": 4, "extend": 1, "fake": 13, "feed": 6, "forward": 6, "frequenc": 8, "from": [3, 6, 7], "function": [7, 12], "futur": 1, "gelu": 6, "gener": [1, 3, 6, 7, 13], "generate_batch": 12, "get": 11, "give": 3, "glove": 15, "gpt": [3, 6, 7], "gpt2": 3, "gptmodel": 3, "gram": 15, "grammar": 3, "guid": 9, "hate": 13, "head": 1, "heurist": 8, "hide": 1, "how": 5, "i": [3, 8, 13], "idf": 8, "implement": [1, 6], "import": [10, 11], "inform": 13, "inner": 3, "input": 1, "instal": 10, "introduct": 5, "invers": 8, "k": 7, "keyword": 13, "knowledg": 13, "languag": [2, 3, 5, 13], "larg": [2, 5], "law": 8, "layer": [1, 6], "learn": 4, "lemmat": [9, 14], "let": 3, "librari": 10, "lightn": 4, "linear": 6, "llm": [5, 6, 7], "load": [3, 7], "long": 1, "loss": 7, "lowercas": 9, "m": 3, "main": 12, "map": 3, "mask": 1, "mechan": 1, "medium": [8, 10], "model": [1, 2, 3, 5, 6, 7, 10, 11, 12, 13], "modifi": 7, "modul": 4, "multi": 1, "multipl": 1, "name": 14, "narrow": 5, "natur": 13, "ner": 14, "network": 6, "new": [12, 13], "nlp": [0, 11, 13], "nltk": 14, "non": 9, "normal": 6, "number": 3, "numeric": 11, "open": 7, "our": [3, 11], "overcom": 13, "overview": 5, "own": 3, "packag": [9, 12], "pad_seq": 3, "part": [1, 3, 14], "perplex": 7, "pipelin": 14, "plai": 3, "posit": 4, "pragmat": 13, "pre": [3, 9], "preprocess": [10, 13, 14], "pretrain": 7, "probabilist": 3, "problem": 1, "process": [5, 9, 12, 13], "project": [9, 10, 11, 12], "punctuat": 9, "put": 9, "pytorch": [4, 7], "random": 7, "rank": 13, "rate": 4, "reason": 13, "recognit": 14, "relat": 13, "remov": [9, 14], "research": 4, "retriev": 13, "sai": 3, "sampl": [3, 7], "save": 7, "scale": 7, "scratch": 6, "self": [1, 4], "selfattent": 1, "semant": 13, "sens": 5, "sequenc": [1, 3, 4], "set": [4, 7, 11], "shortcut": 6, "simpl": 1, "singl": 1, "skip": 15, "someth": 3, "speak": 3, "special": 9, "speech": [3, 13, 14], "split": [1, 10], "stack": 1, "start": 11, "stem": [9, 14], "step": [1, 14], "stop": 14, "stopword": [8, 9], "strategi": 7, "structur": 3, "studi": 4, "syntax": 13, "tag": 14, "task": [11, 12, 13], "temperatur": 7, "term": 8, "test": [3, 10, 11], "text": [6, 7, 9, 10, 13, 14], "tf": 8, "thi": 3, "togeth": 9, "token": [1, 3, 9, 11, 14], "top": 7, "topic": [12, 13], "train": [3, 7, 10, 11, 12], "trainabl": 1, "transform": [3, 4, 6], "trend": 4, "turn": [1, 3, 4, 6, 7, 8, 13, 14, 15], "understand": 3, "unlabel": 7, "up": [3, 4], "us": 7, "valid": [7, 11, 12], "vector": 13, "viceversa": 13, "warm": 4, "weight": [1, 7], "welcom": 0, "what": [5, 13], "why": 9, "without": 1, "word": [1, 3, 14, 15], "word2vec": 15, "work": [5, 12], "you": 3, "your": [1, 3, 4, 6, 7, 8, 13, 14, 15], "zipf": 8, "zmq": 0}})