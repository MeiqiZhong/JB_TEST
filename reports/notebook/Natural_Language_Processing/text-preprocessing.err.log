Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nbclient/client.py", line 1314, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import nltk

# input text
text = "Natural language processing is a field of artificial intelligence that deals with the interaction between computers and human (natural) language."

# tokenize the text
tokens = nltk.word_tokenize(text)

# tag the tokens with their POS tags
tagged_tokens = nltk.pos_tag(tokens)

print("Tagged tokens:", tagged_tokens)
------------------


[0;31m---------------------------------------------------------------------------[0m
[0;31mLookupError[0m                               Traceback (most recent call last)
Cell [0;32mIn[6], line 10[0m
[1;32m      7[0m tokens [38;5;241m=[39m nltk[38;5;241m.[39mword_tokenize(text)
[1;32m      9[0m [38;5;66;03m# tag the tokens with their POS tags[39;00m
[0;32m---> 10[0m tagged_tokens [38;5;241m=[39m [43mnltk[49m[38;5;241;43m.[39;49m[43mpos_tag[49m[43m([49m[43mtokens[49m[43m)[49m
[1;32m     12[0m [38;5;28mprint[39m([38;5;124m"[39m[38;5;124mTagged tokens:[39m[38;5;124m"[39m, tagged_tokens)

File [0;32m/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nltk/tag/__init__.py:165[0m, in [0;36mpos_tag[0;34m(tokens, tagset, lang)[0m
[1;32m    140[0m [38;5;28;01mdef[39;00m [38;5;21mpos_tag[39m(tokens, tagset[38;5;241m=[39m[38;5;28;01mNone[39;00m, lang[38;5;241m=[39m[38;5;124m"[39m[38;5;124meng[39m[38;5;124m"[39m):
[1;32m    141[0m [38;5;250m    [39m[38;5;124;03m"""[39;00m
[1;32m    142[0m [38;5;124;03m    Use NLTK's currently recommended part of speech tagger to[39;00m
[1;32m    143[0m [38;5;124;03m    tag the given list of tokens.[39;00m
[0;32m   (...)[0m
[1;32m    163[0m [38;5;124;03m    :rtype: list(tuple(str, str))[39;00m
[1;32m    164[0m [38;5;124;03m    """[39;00m
[0;32m--> 165[0m     tagger [38;5;241m=[39m [43m_get_tagger[49m[43m([49m[43mlang[49m[43m)[49m
[1;32m    166[0m     [38;5;28;01mreturn[39;00m _pos_tag(tokens, tagset, tagger, lang)

File [0;32m/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nltk/tag/__init__.py:107[0m, in [0;36m_get_tagger[0;34m(lang)[0m
[1;32m    105[0m     tagger[38;5;241m.[39mload(ap_russian_model_loc)
[1;32m    106[0m [38;5;28;01melse[39;00m:
[0;32m--> 107[0m     tagger [38;5;241m=[39m [43mPerceptronTagger[49m[43m([49m[43m)[49m
[1;32m    108[0m [38;5;28;01mreturn[39;00m tagger

File [0;32m/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nltk/tag/perceptron.py:167[0m, in [0;36mPerceptronTagger.__init__[0;34m(self, load)[0m
[1;32m    164[0m [38;5;28mself[39m[38;5;241m.[39mclasses [38;5;241m=[39m [38;5;28mset[39m()
[1;32m    165[0m [38;5;28;01mif[39;00m load:
[1;32m    166[0m     AP_MODEL_LOC [38;5;241m=[39m [38;5;124m"[39m[38;5;124mfile:[39m[38;5;124m"[39m [38;5;241m+[39m [38;5;28mstr[39m(
[0;32m--> 167[0m         [43mfind[49m[43m([49m[38;5;124;43m"[39;49m[38;5;124;43mtaggers/averaged_perceptron_tagger/[39;49m[38;5;124;43m"[39;49m[43m [49m[38;5;241;43m+[39;49m[43m [49m[43mPICKLE[49m[43m)[49m
[1;32m    168[0m     )
[1;32m    169[0m     [38;5;28mself[39m[38;5;241m.[39mload(AP_MODEL_LOC)

File [0;32m/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nltk/data.py:583[0m, in [0;36mfind[0;34m(resource_name, paths)[0m
[1;32m    581[0m sep [38;5;241m=[39m [38;5;124m"[39m[38;5;124m*[39m[38;5;124m"[39m [38;5;241m*[39m [38;5;241m70[39m
[1;32m    582[0m resource_not_found [38;5;241m=[39m [38;5;124mf[39m[38;5;124m"[39m[38;5;130;01m\n[39;00m[38;5;132;01m{[39;00msep[38;5;132;01m}[39;00m[38;5;130;01m\n[39;00m[38;5;132;01m{[39;00mmsg[38;5;132;01m}[39;00m[38;5;130;01m\n[39;00m[38;5;132;01m{[39;00msep[38;5;132;01m}[39;00m[38;5;130;01m\n[39;00m[38;5;124m"[39m
[0;32m--> 583[0m [38;5;28;01mraise[39;00m [38;5;167;01mLookupError[39;00m(resource_not_found)

[0;31mLookupError[0m: 
**********************************************************************
  Resource [93maveraged_perceptron_tagger[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('averaged_perceptron_tagger')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle[0m

  Searched in:
    - '/home/runner/nltk_data'
    - '/opt/hostedtoolcache/Python/3.9.19/x64/nltk_data'
    - '/opt/hostedtoolcache/Python/3.9.19/x64/share/nltk_data'
    - '/opt/hostedtoolcache/Python/3.9.19/x64/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************


